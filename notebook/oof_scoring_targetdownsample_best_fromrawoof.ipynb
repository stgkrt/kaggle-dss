{"cells":[{"cell_type":"markdown","metadata":{},"source":["# check oof df"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-09-20T12:42:51.678091Z","iopub.status.busy":"2023-09-20T12:42:51.677683Z","iopub.status.idle":"2023-09-20T12:43:00.424827Z","shell.execute_reply":"2023-09-20T12:43:00.423819Z","shell.execute_reply.started":"2023-09-20T12:42:51.678056Z"},"trusted":true},"outputs":[],"source":["import os\n","import gc\n","import yaml\n","import argparse\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import torch\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import sys\n","sys.path.append(\"/kaggle/src/dss_utils\")\n","sys.path.append(\"/kaggle/src/exp\")\n","sys.path.append(\"/kaggle/src/model\")\n","sys.path.append(\"/kaggle/src/data\")\n","from dss_metrics import score\n","from training_loop import get_valid_values_dict, concat_valid_input_info, get_oof_df, get_key_df\n","from dss_model import get_model\n","from dss_dataloader import get_loader\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["fold 0\n"]},{"name":"stdout","output_type":"stream","text":["fold 1\n","fold 2\n","fold 3\n","fold 4\n","277\n"]}],"source":["output_dir = \"/kaggle/working\"\n","# exp_name = \"exp017_inputtargettd_flip_epoch10\"\n","# exp_name = \"exp018_inputtargetd_hour_notflip_epoch10\"\n","# exp_name = \"exp020_dense_chh_epoch10\"\n","# exp_name = \"exp020_dense_chh_skffold_epoch30\"\n","# exp_name = \"exp021_dense_chh_skffold_removesomeseries_epoch30\"\n","exp_name = \"exp022_dense_skffold_removesomeseries_epoch10\"\n","folds = [0, 1, 2, 3, 4]\n","# folds = [0]\n","oof_df = pd.DataFrame()\n","for i in folds:\n","    print(\"fold\", i)\n","    df = pd.read_parquet(os.path.join(output_dir, \"_oof\", exp_name, f\"raw_oof_df_fold{i}.parquet\"))\n","    # df = pd.read_parquet(os.path.join(output_dir, \"_oof\", exp_name, f\"fold{i}_best_oof_df.parquet\"))\n","    oof_df = pd.concat([oof_df, df], axis=0)\n","\n","\n","print(len(oof_df[\"series_id\"].unique()))   \n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>series_id</th>\n","      <th>step</th>\n","      <th>second</th>\n","      <th>class_pred</th>\n","      <th>class_target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>038441c925bb</td>\n","      <td>0.0</td>\n","      <td>0</td>\n","      <td>0.197434</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>038441c925bb</td>\n","      <td>1.0</td>\n","      <td>5</td>\n","      <td>0.122130</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>038441c925bb</td>\n","      <td>2.0</td>\n","      <td>10</td>\n","      <td>0.120641</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>038441c925bb</td>\n","      <td>3.0</td>\n","      <td>15</td>\n","      <td>0.114781</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>038441c925bb</td>\n","      <td>4.0</td>\n","      <td>20</td>\n","      <td>0.110041</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>25500432</th>\n","      <td>fe90110788d2</td>\n","      <td>592375.0</td>\n","      <td>35</td>\n","      <td>0.248684</td>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>25500433</th>\n","      <td>fe90110788d2</td>\n","      <td>592376.0</td>\n","      <td>40</td>\n","      <td>0.247514</td>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>25500434</th>\n","      <td>fe90110788d2</td>\n","      <td>592377.0</td>\n","      <td>45</td>\n","      <td>0.245575</td>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>25500435</th>\n","      <td>fe90110788d2</td>\n","      <td>592378.0</td>\n","      <td>50</td>\n","      <td>0.243068</td>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>25500436</th>\n","      <td>fe90110788d2</td>\n","      <td>592379.0</td>\n","      <td>55</td>\n","      <td>0.240075</td>\n","      <td>-1.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>127950909 rows × 5 columns</p>\n","</div>"],"text/plain":["             series_id      step  second  class_pred  class_target\n","0         038441c925bb       0.0       0    0.197434           0.0\n","1         038441c925bb       1.0       5    0.122130           0.0\n","2         038441c925bb       2.0      10    0.120641           0.0\n","3         038441c925bb       3.0      15    0.114781           0.0\n","4         038441c925bb       4.0      20    0.110041           0.0\n","...                ...       ...     ...         ...           ...\n","25500432  fe90110788d2  592375.0      35    0.248684          -1.0\n","25500433  fe90110788d2  592376.0      40    0.247514          -1.0\n","25500434  fe90110788d2  592377.0      45    0.245575          -1.0\n","25500435  fe90110788d2  592378.0      50    0.243068          -1.0\n","25500436  fe90110788d2  592379.0      55    0.240075          -1.0\n","\n","[127950909 rows x 5 columns]"]},"metadata":{},"output_type":"display_data"}],"source":["oof_df = oof_df.sort_values([\"series_id\", \"step\"])\n","display(oof_df)\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# postprocess_fn\n","# series_idでgroupbyして、class_predに対して対象の列のデータから前のN個の列までのデータの平均をとる\n","import torch\n","import torch.nn as nn\n","\n","\n","def postprocess_notrolling(df):\n","    df = df.copy()\n","    df = df[df[\"second\"]==0].reset_index(drop=True)\n","    # 一つ前のclass_predを取得\n","    df[\"class_pred_before\"] = df.groupby(\"series_id\")[\"class_pred\"].shift(1)\n","    # 一つ後のclass_predを取得\n","    df[\"class_pred_after\"] = df.groupby(\"series_id\")[\"class_pred\"].shift(-1)\n","    df[\"event_pred\"] = df[\"class_pred_before\"] - df[\"class_pred_after\"]\n","    not_predicted_mask = (df[\"class_pred\"] != -1).astype(int)\n","    df[\"event_pred\"] = df[\"event_pred\"] * not_predicted_mask\n","    df = df.drop([\"class_pred_before\", \"class_pred_after\"], axis=1)\n","    return df\n","\n","# 1step 0.5secで30minなら60*30=1800step\n","def postprocess_downsample_fn(df, N=3, maxpool_kernel_size=3, maxpool_stride=1):\n","    df = df.copy()\n","    df = df[df[\"second\"]==0].reset_index(drop=True)\n","    df[\"class_pred_beforemean\"] = df.groupby(\"series_id\")[\"class_pred\"].apply(lambda x: x.rolling(N, min_periods=1).mean())\n","    df[\"class_pred_aftermean\"] = df.groupby(\"series_id\")[\"class_pred\"].apply(lambda x: x[::-1].rolling(N, min_periods=1).mean()[::-1])\n","    df[\"event_pred\"] = df[\"class_pred_beforemean\"] - df[\"class_pred_aftermean\"]\n","    not_predicted_mask = (df[\"class_pred\"] != -1).astype(int)\n","    df[\"event_pred\"] = df[\"event_pred\"] * not_predicted_mask\n","\n","    # 入力サイズと出力サイズが一致するようにpaddingを調整\n","    maxpool_padding = int((maxpool_kernel_size - maxpool_stride) / 2)\n","    # maxpoolしてピーク検出\n","    max_pooling = nn.MaxPool1d(maxpool_kernel_size, stride=maxpool_stride, padding=maxpool_padding)\n","    event_pred = df[\"event_pred\"].values\n","    event_pred = torch.tensor(event_pred).unsqueeze(0)\n","    pooled_event_pred = max_pooling(np.abs(event_pred)).squeeze(0).numpy()\n","    event_pred = event_pred.squeeze(0).numpy()\n","    # peakのところだけ残すmaskを作成\n","    peak_event_pred_mask = np.where(pooled_event_pred == np.abs(event_pred), 1, 0)\n","    peak_event_pred = event_pred * peak_event_pred_mask\n","    df[\"event_pred\"] = peak_event_pred\n","    df = df.drop([\"class_pred_beforemean\", \"class_pred_aftermean\"], axis=1)\n","    return df\n","\n","def postprocess_downsample_notmaxpool(df, N=11):\n","    df = df.copy()\n","    df[\"class_pred_beforemean\"] = df.groupby(\"series_id\")[\"class_pred\"].apply(lambda x: x.rolling(N, min_periods=1).mean())\n","    df[\"class_pred_aftermean\"] = df.groupby(\"series_id\")[\"class_pred\"].apply(lambda x: x[::-1].rolling(N, min_periods=1).mean()[::-1])\n","    df[\"event_pred\"] = df[\"class_pred_beforemean\"] - df[\"class_pred_aftermean\"]\n","    df = df.drop([\"class_pred_beforemean\", \"class_pred_aftermean\"], axis=1)\n","    return df\n","\n","def make_submission_df(df, threshold=0.1):\n","    df = df[[\"series_id\", \"step\", \"event_pred\"]].copy()\n","    # thresholdより大きいときは1,-thresholdより小さいときは-1,それ以外は0\n","    df[\"event\"] = df[\"event_pred\"].apply(lambda x: 1 if x > threshold else -1 if x < -threshold else 0)\n","    df = df[df[\"event\"] != 0].copy()\n","    df[\"event\"] = df[\"event\"].replace({1: \"wakeup\", -1: \"onset\"})\n","    df[\"score\"] = df[\"event_pred\"].apply(lambda x: np.clip(np.abs(x), 0.0, 1.0))\n","    return df\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>series_id</th>\n","      <th>night</th>\n","      <th>event</th>\n","      <th>step</th>\n","      <th>timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>038441c925bb</td>\n","      <td>1</td>\n","      <td>onset</td>\n","      <td>4992.0</td>\n","      <td>2018-08-14T22:26:00-0400</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>038441c925bb</td>\n","      <td>1</td>\n","      <td>wakeup</td>\n","      <td>10932.0</td>\n","      <td>2018-08-15T06:41:00-0400</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>038441c925bb</td>\n","      <td>2</td>\n","      <td>onset</td>\n","      <td>20244.0</td>\n","      <td>2018-08-15T19:37:00-0400</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>038441c925bb</td>\n","      <td>2</td>\n","      <td>wakeup</td>\n","      <td>27492.0</td>\n","      <td>2018-08-16T05:41:00-0400</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>038441c925bb</td>\n","      <td>3</td>\n","      <td>onset</td>\n","      <td>39996.0</td>\n","      <td>2018-08-16T23:03:00-0400</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      series_id  night   event     step                 timestamp\n","0  038441c925bb      1   onset   4992.0  2018-08-14T22:26:00-0400\n","1  038441c925bb      1  wakeup  10932.0  2018-08-15T06:41:00-0400\n","2  038441c925bb      2   onset  20244.0  2018-08-15T19:37:00-0400\n","3  038441c925bb      2  wakeup  27492.0  2018-08-16T05:41:00-0400\n","4  038441c925bb      3   onset  39996.0  2018-08-16T23:03:00-0400"]},"metadata":{},"output_type":"display_data"}],"source":["train_event_df = pd.read_csv(\"/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv\")\n","train_event_df = train_event_df[train_event_df[\"step\"].notnull()].copy()\n","# train_event_df = train_event_df[train_event_df[\"series_id\"].isin(oof_df[\"series_id\"].unique())].copy()\n","train_event_df = train_event_df.reset_index(drop=True)\n","display(train_event_df.head())\n"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>series_id</th>\n","      <th>step</th>\n","      <th>event_pred</th>\n","      <th>event</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>038441c925bb</td>\n","      <td>12.0</td>\n","      <td>0.149492</td>\n","      <td>wakeup</td>\n","      <td>0.149492</td>\n","    </tr>\n","    <tr>\n","      <th>248</th>\n","      <td>038441c925bb</td>\n","      <td>2976.0</td>\n","      <td>-0.155928</td>\n","      <td>onset</td>\n","      <td>0.155928</td>\n","    </tr>\n","    <tr>\n","      <th>249</th>\n","      <td>038441c925bb</td>\n","      <td>2988.0</td>\n","      <td>-0.214665</td>\n","      <td>onset</td>\n","      <td>0.214665</td>\n","    </tr>\n","    <tr>\n","      <th>259</th>\n","      <td>038441c925bb</td>\n","      <td>3108.0</td>\n","      <td>-0.165041</td>\n","      <td>onset</td>\n","      <td>0.165041</td>\n","    </tr>\n","    <tr>\n","      <th>262</th>\n","      <td>038441c925bb</td>\n","      <td>3144.0</td>\n","      <td>0.100421</td>\n","      <td>wakeup</td>\n","      <td>0.100421</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        series_id    step  event_pred   event     score\n","1    038441c925bb    12.0    0.149492  wakeup  0.149492\n","248  038441c925bb  2976.0   -0.155928   onset  0.155928\n","249  038441c925bb  2988.0   -0.214665   onset  0.214665\n","259  038441c925bb  3108.0   -0.165041   onset  0.165041\n","262  038441c925bb  3144.0    0.100421  wakeup  0.100421"]},"metadata":{},"output_type":"display_data"}],"source":["df = postprocess_notrolling(oof_df)\n","sub_df = make_submission_df(df, threshold=0.1)\n","display(sub_df.head())\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.4789030916587436\n"]}],"source":["oof_notroll_score = score(train_event_df, sub_df)\n","print(oof_notroll_score)\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# average_size = 31\n","# max_kernel_size = 31\n","# df = postprocess_downsample_fn(oof_df, N=average_size, maxpool_kernel_size=max_kernel_size)\n","# sub_df = make_submission_df(df, threshold=0.1)\n","# ave_maxpool_score = score(train_event_df, sub_df)\n","# print(ave_maxpool_score)\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["average_size 3 max_kernel_size 3\n","0.6653744185706514\n","average_size 5 max_kernel_size 3\n","0.6806556915724529\n","average_size 7 max_kernel_size 3\n","0.6879106579128177\n","average_size 9 max_kernel_size 3\n","0.6900668685666205\n","average_size 11 max_kernel_size 3\n","0.6902450772832444\n","average_size 13 max_kernel_size 3\n","0.6900412312691349\n","CPU times: user 1min 11s, sys: 8.69 s, total: 1min 20s\n","Wall time: 1min 16s\n"]}],"source":["%%time\n","max_kernel_size = 3\n","tmp_score = 0\n","for average_size_ in range(3, 21, 2):\n","    print(\"average_size\", average_size_, \"max_kernel_size\", max_kernel_size)\n","    df = postprocess_downsample_fn(oof_df, N=average_size_, maxpool_kernel_size=max_kernel_size)\n","    sub_df = make_submission_df(df, threshold=0.1)\n","    if len(sub_df) == 0:\n","        print(\"event not detected\")\n","        continuprint(len(sub_df))\n","    score_ = score(train_event_df, sub_df)\n","    print(score_)\n","    if tmp_score > score_:\n","        break\n","    tmp_score = score_\n","    average_size = average_size_\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["average_size 11 max_kernel_size 3\n","0.6902450772832444\n","average_size 11 max_kernel_size 5\n","0.6903887377298077\n","average_size 11 max_kernel_size 7\n","0.6901647473318656\n"]}],"source":["tmp_score = 0\n","max_kernel_size_ = max_kernel_size\n","for max_kernel_size in range(3, 31, 2):\n","    print(\"average_size\", average_size, \"max_kernel_size\", max_kernel_size)\n","    df = postprocess_downsample_fn(oof_df, N=average_size, maxpool_kernel_size=max_kernel_size)\n","    sub_df = make_submission_df(df, threshold=0.1)\n","    if len(sub_df) == 0:\n","        print(\"event not detected\")\n","        continue\n","    score_ = score(train_event_df, sub_df)\n","    print(score_)\n","    if tmp_score > score_:\n","        break\n","    tmp_score = score_\n","    max_kernel_size_ = max_kernel_size\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["11 5\n","0.6994817648095175\n"]}],"source":["df = postprocess_downsample_fn(oof_df, N=average_size, maxpool_kernel_size=max_kernel_size_)\n","sub_df = make_submission_df(df, threshold=0.01)\n","print(average_size, max_kernel_size_)\n","\n","if len(sub_df) == 0:\n","    print(\"event not detected\")\n","    score_ = 0\n","else:\n","    score_ = score(train_event_df, sub_df)\n","print(score_)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
