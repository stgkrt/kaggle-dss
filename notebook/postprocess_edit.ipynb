{"cells":[{"cell_type":"markdown","metadata":{},"source":["# check oof df"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-09-20T12:42:51.678091Z","iopub.status.busy":"2023-09-20T12:42:51.677683Z","iopub.status.idle":"2023-09-20T12:43:00.424827Z","shell.execute_reply":"2023-09-20T12:43:00.423819Z","shell.execute_reply.started":"2023-09-20T12:42:51.678056Z"},"trusted":true},"outputs":[],"source":["import os\n","\n","import numpy as np\n","import pandas as pd\n","from pandarallel import pandarallel\n","import matplotlib.pyplot as plt\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', 500)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["output_dir = os.path.join(\"/kaggle\", \"working\", \"_oof\")\n","# exp_name = \"baseline000\"\n","# exp_name = \"baseline000_1697037446.0796616\"\n","# exp_name = \"baseline_alldata_allfold_000\"\n","exp_name = \"exp005_lossbugfixed_lr\"\n","# oof_df_path = os.path.join(output_dir, exp_name,\"oof_df.parquet\")\n","# oof_df = pd.read_parquet(oof_df_path)\n","# for i in range(5):\n","#     print(\"fold\", i)\n","#     oof_df = pd.concat(\n","#         [pd.read_parquet(os.path.join(output_dir, exp_name, f\"oof_df_fold{i}.parquet\"))]\n","#         ,axis=0\n","#     )"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# postprocess_fn\n","# series_idでgroupbyして、class_predに対して対象の列のデータから前のN個の列までのデータの平均をとる\n","import torch\n","import torch.nn as nn\n","\n","# 1step 0.5secで30minなら60*30=1800step\n","def postprocess_fn(df, N=1800, maxpool_kernel_size=101, maxpool_stride=1):\n","    df = df.copy()\n","    df[\"class_pred_beforemean\"] = df.groupby(\"series_id\")[\"class_pred\"].apply(lambda x: x.rolling(N, min_periods=1).mean())\n","    df[\"class_pred_aftermean\"] = df.groupby(\"series_id\")[\"class_pred\"].apply(lambda x: x[::-1].rolling(N, min_periods=1).mean()[::-1])\n","    df[\"event_pred\"] = df[\"class_pred_beforemean\"] - df[\"class_pred_aftermean\"]\n","\n","    # 入力サイズと出力サイズが一致するようにpaddingを調整\n","    maxpool_padding = int((maxpool_kernel_size - maxpool_stride) / 2)\n","    # maxpoolしてピーク検出\n","    max_pooling = nn.MaxPool1d(maxpool_kernel_size, stride=maxpool_stride, padding=maxpool_padding)\n","    event_pred = df[\"event_pred\"].values\n","    event_pred = torch.tensor(event_pred).unsqueeze(0)\n","    pooled_event_pred = max_pooling(np.abs(event_pred)).squeeze(0).numpy()\n","    event_pred = event_pred.squeeze(0).numpy()\n","    # peakのところだけ残すmaskを作成\n","    peak_event_pred_mask = np.where(pooled_event_pred == np.abs(event_pred), 1, 0)\n","    peak_event_pred = event_pred * peak_event_pred_mask\n","    df[\"event_pred\"] = peak_event_pred\n","    df = df.drop([\"class_pred_beforemean\", \"class_pred_aftermean\"], axis=1)\n","    return df\n","\n","\n","def make_submission_df(df, threshold=0.0):\n","    df = df[[\"series_id\", \"step\", \"event_pred\"]].copy()\n","    # thresholdより大きいときは1,-thresholdより小さいときは-1,それ以外は0\n","    df[\"event\"] = df[\"event_pred\"].apply(lambda x: 1 if x > threshold else -1 if x < -threshold else 0)\n","    df = df[df[\"event\"] != 0].copy()\n","    df[\"event\"] = df[\"event\"].replace({1: \"wakeup\", -1: \"onset\"})\n","    df[\"score\"] = df[\"event_pred\"].apply(lambda x: np.clip(np.abs(x), 0.0, 1.0))\n","    return df\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>series_id</th>\n","      <th>night</th>\n","      <th>event</th>\n","      <th>step</th>\n","      <th>timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>038441c925bb</td>\n","      <td>1</td>\n","      <td>onset</td>\n","      <td>4992.0</td>\n","      <td>2018-08-14T22:26:00-0400</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>038441c925bb</td>\n","      <td>1</td>\n","      <td>wakeup</td>\n","      <td>10932.0</td>\n","      <td>2018-08-15T06:41:00-0400</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>038441c925bb</td>\n","      <td>2</td>\n","      <td>onset</td>\n","      <td>20244.0</td>\n","      <td>2018-08-15T19:37:00-0400</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>038441c925bb</td>\n","      <td>2</td>\n","      <td>wakeup</td>\n","      <td>27492.0</td>\n","      <td>2018-08-16T05:41:00-0400</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>038441c925bb</td>\n","      <td>3</td>\n","      <td>onset</td>\n","      <td>39996.0</td>\n","      <td>2018-08-16T23:03:00-0400</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      series_id  night   event     step                 timestamp\n","0  038441c925bb      1   onset   4992.0  2018-08-14T22:26:00-0400\n","1  038441c925bb      1  wakeup  10932.0  2018-08-15T06:41:00-0400\n","2  038441c925bb      2   onset  20244.0  2018-08-15T19:37:00-0400\n","3  038441c925bb      2  wakeup  27492.0  2018-08-16T05:41:00-0400\n","4  038441c925bb      3   onset  39996.0  2018-08-16T23:03:00-0400"]},"metadata":{},"output_type":"display_data"}],"source":["train_event_df = pd.read_csv(\"/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv\")\n","# train_event_df = train_event_df[train_event_df[\"series_id\"].isin(oof_df[\"series_id\"].unique())].copy()\n","# train_event_df = train_event_df.reset_index(drop=True)\n","display(train_event_df.head())"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["import sys\n","sys.path.append(\"/kaggle/src/dss_utils\")\n","\n","# series_id_column_name = \"series_id\"\n","# time_column_name = \"step\"\n","# event_column_name = \"event\"\n","# score_column_name = \"score\"\n","# use_scoring_intervals = None  # type:ignore\n","\n","\n","# # [1, 3, 5, 7, 10, 13, 15, 20, 25, 30] minute\n","# tolerances = {\n","#     \"onset\": [12, 36, 60, 90, 120, 150, 180, 240, 300, 360],\n","#     \"wakeup\": [12, 36, 60, 90, 120, 150, 180, 240, 300, 360],\n","# }\n","\n","from dss_metrics import score"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["event_df = train_event_df[train_event_df[\"step\"].notnull()].copy()"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["fold0 score: 0.6622583576166272\n","fold1 score: 0.666057093356913\n","fold2 score: 0.6405538667346251\n","fold3 score: 0.6514126108078131\n","fold4 score: 0.640819494291069\n"]}],"source":["oof_df = pd.DataFrame()\n","for i in range(5):\n","    oof_df_fold = pd.read_parquet(os.path.join(output_dir, exp_name, f\"oof_df_fold{i}.parquet\"))\n","    df = postprocess_fn(oof_df_fold)\n","    sub_df = make_submission_df(df, threshold=0.01)\n","    event_fold_df = event_df[event_df[\"series_id\"].isin(oof_df_fold[\"series_id\"].unique())].copy()\n","    fold_score = score(event_fold_df, sub_df)\n","    print(f\"fold{i} score:\", fold_score)\n","    oof_df = pd.concat([oof_df, sub_df], axis=0)\n","oof_df = oof_df.reset_index(drop=True)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["all score: 0.6483557411310146\n"]}],"source":["# df = postprocess_fn(oof_df)\n","# sub_df = make_submission_df(df, threshold=0.01)\n","event_all_df = event_df[event_df[\"series_id\"].isin(oof_df[\"series_id\"].unique())].copy()\n","all_score = score(event_all_df, oof_df)\n","print(f\"all score:\", all_score)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["series_ids = set(event_df[\"series_id\"].unique()) - set(oof_df[\"series_id\"].unique())\n","print(len(series_ids))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%%time\n","max_kernel_size = 41\n","tmp_score = 0\n","for average_size_ in range(101, 1001, 100):\n","    print(\"average_size\", average_size_, \"max_kernel_size\", max_kernel_size, end=\" \")\n","    df = postprocess_fn(oof_df, N=average_size_, maxpool_kernel_size=max_kernel_size)\n","    print(\"postprocessed\", end=\" \")\n","    sub_df = make_submission_df(df, threshold=0.01)\n","    print(\"submission\", end=\" \")\n","    score_ = score(event_df, sub_df)\n","    print(score_)\n","    if tmp_score > score_:\n","        break\n","    tmp_score = score_\n","    average_size = average_size_"]},{"cell_type":"markdown","metadata":{},"source":["threshold 0\n","average_size 101 max_kernel_size 41 postprocessed submission 0.6363470035624408\n","average_size 201 max_kernel_size 41 postprocessed submission 0.6499744712492275"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# tmp_score = 0\n","# for max_kernel_size in range(21, 201, 20):\n","#     print(\"average_size\", average_size, \"max_kernel_size\", max_kernel_size)\n","#     df = postprocess_fn(oof_df, N=average_size, maxpool_kernel_size=max_kernel_size)\n","#     sub_df = make_submission_df(df, threshold=0.0)\n","#     score_ = score(event_df, sub_df)\n","#     print(score_)\n","#     if tmp_score > score_:\n","#         break\n","#     tmp_score = score_"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tmp_score = 0\n","for average_size_ in range(101, 1001, 100):\n","    print(\"average_size\", average_size_)\n","    df = postprocess_fn(oof_df, N=average_size_, maxpool_kernel_size=3)\n","    sub_df = make_submission_df(df, threshold=0.01)\n","    score_ = score(event_df, sub_df)\n","    print(score_)\n","    if tmp_score > score_:\n","        break\n","    tmp_score = score_\n","    average_size = average_size_"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
