{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3a5118a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-12T01:52:03.339766Z",
     "iopub.status.busy": "2023-11-12T01:52:03.339428Z",
     "iopub.status.idle": "2023-11-12T01:52:04.228984Z",
     "shell.execute_reply": "2023-11-12T01:52:04.228216Z"
    },
    "papermill": {
     "duration": 0.898991,
     "end_time": "2023-11-12T01:52:04.231270",
     "exception": false,
     "start_time": "2023-11-12T01:52:03.332279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import argparse\n",
    "import yaml\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1257a2c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T01:52:04.243524Z",
     "iopub.status.busy": "2023-11-12T01:52:04.243125Z",
     "iopub.status.idle": "2023-11-12T01:52:09.286998Z",
     "shell.execute_reply": "2023-11-12T01:52:09.286073Z"
    },
    "papermill": {
     "duration": 5.052388,
     "end_time": "2023-11-12T01:52:09.289312",
     "exception": false,
     "start_time": "2023-11-12T01:52:04.236924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"/kaggle/src/exp\")\n",
    "sys.path.append(\"/kaggle/src/data\")\n",
    "sys.path.append(\"/kaggle/src/model\")\n",
    "sys.path.append(\"/kaggle/src/dss_utils\")\n",
    "# sys.path.append(\"/kaggle/src/submission\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from dss_dataloader import get_loader\n",
    "from dss_model import get_model\n",
    "from training_loop import concat_valid_input_info, get_valid_values_dict, seed_everything\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aba2b69c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T01:52:09.301162Z",
     "iopub.status.busy": "2023-11-12T01:52:09.300771Z",
     "iopub.status.idle": "2023-11-12T01:52:09.306575Z",
     "shell.execute_reply": "2023-11-12T01:52:09.305650Z"
    },
    "papermill": {
     "duration": 0.013785,
     "end_time": "2023-11-12T01:52:09.308454",
     "exception": false,
     "start_time": "2023-11-12T01:52:09.294669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# exp_dir = \"/kaggle/input/dss-exps\"\n",
    "exp_dir = \"/kaggle/working\"\n",
    "exp_name = \"exp020_dense_chh_skffold_epoch30\" # exp020_dense_chh_skffold_epoch30からbest modelを保存するようになった\n",
    "# series_df_path = \"/kaggle/input/dss-train-someunique-series/train_series.parquet\"\n",
    "series_df_path = \"/kaggle/input/child-mind-institute-detect-sleep-states/train_series.parquet\"\n",
    "config_path = os.path.join(exp_dir, exp_name, \"config.yaml\")\n",
    "\n",
    "tmp_file_path = \"/kaggle/working/tmp\"\n",
    "os.makedirs(tmp_file_path, exist_ok=True)\n",
    "\n",
    "class_pred_roll_mean_num = 11\n",
    "class_pred_maxpool_num = 3\n",
    "\n",
    "dataframe_split_num = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4dc460",
   "metadata": {
    "papermill": {
     "duration": 0.004844,
     "end_time": "2023-11-12T01:52:09.318356",
     "exception": false,
     "start_time": "2023-11-12T01:52:09.313512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1677f9a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T01:52:09.329666Z",
     "iopub.status.busy": "2023-11-12T01:52:09.329352Z",
     "iopub.status.idle": "2023-11-12T01:52:09.342968Z",
     "shell.execute_reply": "2023-11-12T01:52:09.342103Z"
    },
    "papermill": {
     "duration": 0.021634,
     "end_time": "2023-11-12T01:52:09.344939",
     "exception": false,
     "start_time": "2023-11-12T01:52:09.323305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pl_datetime_preprocess(train_series_):\n",
    "    train_series_ = train_series_.with_columns(\n",
    "        pl.col(\"timestamp\").str.to_datetime().dt.replace_time_zone(None))\n",
    "    train_series_ = train_series_.with_columns(\n",
    "        pl.col(\"timestamp\").dt.second().cast(pl.Int32).alias(\"second\"))\n",
    "    train_series_ = train_series_.with_columns(\n",
    "        pl.col(\"timestamp\").dt.minute().cast(pl.Int32).alias(\"minute\"))\n",
    "    train_series_ = train_series_.with_columns(\n",
    "        pl.col(\"timestamp\").dt.date().cast(str).alias(\"date\"))\n",
    "    return train_series_\n",
    "\n",
    "\n",
    "def preprocess_input(train_series_: pd.DataFrame) -> pd.DataFrame:\n",
    "    train_series_ = train_series_.drop(columns=[\"timestamp\"], axis=1)\n",
    "    # anglezとenmoのrolling meanとrolling stdを取る\n",
    "    print(\"get anglez and enmo rolling mean and std\")\n",
    "    for roll_num in [36, 60]:  # 雰囲気で選んだ\n",
    "        train_series_[f\"anglez_mean_{roll_num}\"] = (\n",
    "            train_series_.groupby(\"series_id\")[\"anglez\"].rolling(\n",
    "                roll_num, center=True).mean().reset_index(0, drop=True))\n",
    "        train_series_[f\"anglez_std_{roll_num}\"] = (\n",
    "            train_series_.groupby(\"series_id\")[\"anglez\"].rolling(\n",
    "                roll_num, center=True).std().reset_index(0, drop=True))\n",
    "        train_series_[f\"anglez_mean_{roll_num}\"] = train_series_[\n",
    "            f\"anglez_mean_{roll_num}\"].fillna(0)\n",
    "        train_series_[f\"anglez_std_{roll_num}\"] = train_series_[\n",
    "            f\"anglez_std_{roll_num}\"].fillna(0)    \n",
    "    return train_series_\n",
    "\n",
    "\n",
    "def set_seriesdatekey(train_series_: pd.DataFrame) -> pd.DataFrame:\n",
    "    train_series_[\"series_date_key\"] = (\n",
    "        train_series_[\"series_id\"].astype(str) + \"_\" + train_series_[\"date\"].astype(str)\n",
    "    )\n",
    "    return train_series_\n",
    "\n",
    "def label_encode_series_date_key(train_series_: pd.DataFrame) -> pd.DataFrame:\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    train_series_[\"series_date_key_str\"] = train_series_[\"series_date_key\"].astype(str)\n",
    "    train_series_[\"series_date_key\"] = le.fit_transform(\n",
    "        train_series_[\"series_date_key_str\"]\n",
    "    )\n",
    "    train_series_[\"series_date_key\"] = train_series_[\"series_date_key\"].astype(\"int64\")\n",
    "    return train_series_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ee4b6c",
   "metadata": {
    "papermill": {
     "duration": 0.004739,
     "end_time": "2023-11-12T01:52:09.354682",
     "exception": false,
     "start_time": "2023-11-12T01:52:09.349943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# post process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4f21140",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T01:52:09.365891Z",
     "iopub.status.busy": "2023-11-12T01:52:09.365626Z",
     "iopub.status.idle": "2023-11-12T01:52:09.378889Z",
     "shell.execute_reply": "2023-11-12T01:52:09.378077Z"
    },
    "papermill": {
     "duration": 0.021115,
     "end_time": "2023-11-12T01:52:09.380734",
     "exception": false,
     "start_time": "2023-11-12T01:52:09.359619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1step 0.5secで30minなら60*30=1800step?\n",
    "# metric的にいっぱい検出してもいい？とりあえず小さめ\n",
    "def detect_event_from_downsample_classpred(df,tmp_file_path\n",
    "                                           N=class_pred_roll_mean_num,\n",
    "                                           maxpool_kernel_size=class_pred_maxpool_num,\n",
    "                                           maxpool_stride=1\n",
    "                                           ):\n",
    "    df = df[df[\"second\"] == 0].reset_index(drop=True)\n",
    "    df = df.sort_values([\"series_id\", \"step\"]).reset_index(drop=True)\n",
    "    df[\"class_pred_beforemean\"] = df.groupby(\"series_id\")[\"class_pred\"].apply(\n",
    "        lambda x: x.rolling(N, min_periods=1).mean()\n",
    "    ).reset_index(drop=True)\n",
    "    df[\"class_pred_aftermean\"] = df.groupby(\"series_id\")[\"class_pred\"].apply(\n",
    "        lambda x: x[::-1].rolling(N, min_periods=1).mean()[::-1]\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    df[\"event_pred\"] = df[\"class_pred_beforemean\"] - df[\"class_pred_aftermean\"]\n",
    "    not_predicted_mask = (df[\"class_pred\"] != -1).astype(int)\n",
    "    df[\"event_pred\"] = df[\"event_pred\"] * not_predicted_mask\n",
    "\n",
    "    # 入力サイズと出力サイズが一致するようにpaddingを調整\n",
    "    maxpool_padding = int((maxpool_kernel_size - maxpool_stride) / 2)\n",
    "    # maxpoolしてピーク検出\n",
    "    max_pooling = nn.MaxPool1d(maxpool_kernel_size,\n",
    "                               stride=maxpool_stride,\n",
    "                               padding=maxpool_padding)\n",
    "    event_pred = df[\"event_pred\"].values\n",
    "    event_pred = torch.tensor(event_pred).unsqueeze(0)\n",
    "    pooled_event_pred = max_pooling(np.abs(event_pred)).squeeze(0).numpy()\n",
    "    event_pred = event_pred.squeeze(0).numpy()\n",
    "    # peakのところだけ残すmaskを作成\n",
    "    peak_event_pred_mask = np.where(pooled_event_pred == np.abs(event_pred), 1, 0)\n",
    "    peak_event_pred = event_pred * peak_event_pred_mask\n",
    "    df[\"event_pred\"] = peak_event_pred\n",
    "    df[\"onset_pred\"] = np.clip(-df[\"event_pred\"], 0, 1)\n",
    "    df[\"wakeup_pred\"] = np.clip(df[\"event_pred\"], 0, 1)\n",
    "    df = df.drop([\"class_pred_beforemean\", \"class_pred_aftermean\"], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_submission_df(df, threshold=0.01):\n",
    "    df = df[[\"series_id\", \"step\", \"event_pred\"]]\n",
    "    # thresholdより大きいときは1,-thresholdより小さいときは-1,それ以外は0\n",
    "    df[\"event\"] = df[\"event_pred\"].apply(\n",
    "        lambda x: 1 if x > threshold else -1 if x < -threshold else 0\n",
    "    )\n",
    "    df = df[df[\"event\"] != 0]\n",
    "    df[\"event\"] = df[\"event\"].replace({1: \"wakeup\", -1: \"onset\"})\n",
    "    df[\"score\"] = df[\"event_pred\"].apply(lambda x: np.clip(np.abs(x), 0.0, 1.0))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cf0013c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T01:52:09.392662Z",
     "iopub.status.busy": "2023-11-12T01:52:09.392380Z",
     "iopub.status.idle": "2023-11-12T01:52:09.410095Z",
     "shell.execute_reply": "2023-11-12T01:52:09.409220Z"
    },
    "papermill": {
     "duration": 0.025877,
     "end_time": "2023-11-12T01:52:09.411986",
     "exception": false,
     "start_time": "2023-11-12T01:52:09.386109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_valid_values_dict(\n",
    "    class_values: torch.Tensor,\n",
    "    validation_dict: dict,\n",
    "    mode: str = \"preds\",\n",
    ") -> dict:\n",
    "    class_values = class_values.detach().cpu().numpy()\n",
    "    if len(validation_dict[f\"class_{mode}\"]) == 0:\n",
    "        validation_dict[f\"class_{mode}\"] = class_values\n",
    "    else:\n",
    "        validation_dict[f\"class_{mode}\"] = np.concatenate(\n",
    "            [validation_dict[f\"class_{mode}\"], class_values], axis=0)\n",
    "    return validation_dict\n",
    "\n",
    "def concat_valid_input_info(valid_input_info: dict, input_info: dict) -> dict:\n",
    "    if len(valid_input_info[\"series_date_key\"]) == 0:\n",
    "        valid_input_info[\"series_date_key\"] = input_info[\"series_date_key\"].numpy()\n",
    "        valid_input_info[\"start_step\"] = input_info[\"start_step\"].numpy()\n",
    "        valid_input_info[\"end_step\"] = input_info[\"end_step\"].numpy()\n",
    "    else:\n",
    "        valid_input_info[\"series_date_key\"] = np.concatenate([\n",
    "            valid_input_info[\"series_date_key\"], input_info[\"series_date_key\"].numpy()\n",
    "        ],axis=0)\n",
    "        valid_input_info[\"start_step\"] = np.concatenate(\n",
    "            [valid_input_info[\"start_step\"], input_info[\"start_step\"].numpy()], axis=0)\n",
    "        valid_input_info[\"end_step\"] = np.concatenate(\n",
    "            [valid_input_info[\"end_step\"], input_info[\"end_step\"].numpy()], axis=0)\n",
    "    return valid_input_info\n",
    "\n",
    "def get_pred_df(\n",
    "    input_info_dict: dict,\n",
    "    preds_dict: dict,\n",
    "    pred_df: pd.DataFrame,\n",
    "    fold: int,\n",
    ") -> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "    print(\"creating oof_df\", end=\" ... \")\n",
    "    if \"class_pred\" in pred_df.columns:\n",
    "        pred_df = pred_df.drop([\"class_pred\"], axis=1)\n",
    "    series_date_key_list = []\n",
    "    class_pred_list, steps_list = [],  []\n",
    "\n",
    "    for idx, (series_date_key, start_step, end_step) in enumerate(\n",
    "            zip(\n",
    "                input_info_dict[\"series_date_key\"],\n",
    "                input_info_dict[\"start_step\"],\n",
    "                input_info_dict[\"end_step\"],\n",
    "            )):\n",
    "        if not isinstance(series_date_key, np.int64):\n",
    "            series_date_key = series_date_key.numpy()\n",
    "        # preds targets shape: [batch, ch, data_length]\n",
    "        class_pred = preds_dict[\"class_preds\"][idx]\n",
    "        steps = range(start_step, end_step+1, 12)\n",
    "        series_date_data_num = len(steps)\n",
    "        if series_date_data_num < len(class_pred[0]):\n",
    "            class_pred = class_pred[0, :series_date_data_num]\n",
    "        elif series_date_data_num > len(class_pred[0]):\n",
    "            padding_num = series_date_data_num - len(class_pred[0])\n",
    "            class_pred = np.concatenate(\n",
    "                [class_pred[0], -1 * np.ones(padding_num)], axis=0)\n",
    "        else:\n",
    "            class_pred = class_pred[0]\n",
    "        if not (len(class_pred) == len(steps)):\n",
    "            print(\"len(class_pred)\", len(class_pred))\n",
    "            print(\"len(steps)\", len(steps))\n",
    "            raise ValueError(\"preds and step length is not same\")\n",
    "        class_pred_list.extend(class_pred)\n",
    "        steps_list.extend(steps)\n",
    "        series_date_key_list.extend([series_date_key] * len(steps))\n",
    "    pred_col_name = f\"class_pred_fold{fold}\"\n",
    "    oof_pred_target_df = pd.DataFrame({\n",
    "        \"series_date_key\": series_date_key_list,\n",
    "        \"step\": steps_list,\n",
    "        pred_col_name: class_pred_list,\n",
    "    })\n",
    "    merge_start_time = time.time()\n",
    "    print(\"merging oof_df\")\n",
    "    oof_pred_target_df[\"series_date_key\"] = oof_pred_target_df[\"series_date_key\"].astype(\"int64\")\n",
    "    pred_df = pd.merge(pred_df,\n",
    "                       oof_pred_target_df,\n",
    "                       on=[\"series_date_key\", \"step\"],\n",
    "                       how=\"left\")\n",
    "    pred_df[pred_col_name] = pred_df[pred_col_name].fillna(-1)\n",
    "    merge_elapsed = int(time.time() - merge_start_time) / 60\n",
    "    print(\"merge elapsed time: {:.2f} min\".format(merge_elapsed))\n",
    "    elapsed = int(time.time() - start_time) / 60\n",
    "    print(f\" >> oof_df created. elapsed time: {elapsed:.2f} min\")\n",
    "    return pred_df      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c61a98e",
   "metadata": {
    "papermill": {
     "duration": 0.004769,
     "end_time": "2023-11-12T01:52:09.421779",
     "exception": false,
     "start_time": "2023-11-12T01:52:09.417010",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00abc53d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T01:52:09.433242Z",
     "iopub.status.busy": "2023-11-12T01:52:09.432967Z",
     "iopub.status.idle": "2023-11-12T01:52:09.440699Z",
     "shell.execute_reply": "2023-11-12T01:52:09.439844Z"
    },
    "papermill": {
     "duration": 0.01545,
     "end_time": "2023-11-12T01:52:09.442531",
     "exception": false,
     "start_time": "2023-11-12T01:52:09.427081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def split_data(series_df, tmp_file_path, split_num=3):\n",
    "    series_id_unique = series_df[\"series_id\"].unique()\n",
    "    if len(series_id_unique) <= split_num:\n",
    "        df_path = os.path.join(tmp_file_path, f\"series_df_split_0.parquet\")\n",
    "        series_df.to_parquet(df_path, index=False)\n",
    "        split_num = 1\n",
    "    else:\n",
    "        for idx in range(split_num):\n",
    "            if idx == split_num-1:\n",
    "                series_id_split = series_id_unique[idx*(len(series_id_unique) // split_num):]\n",
    "            else:\n",
    "                series_id_split = series_id_unique[\n",
    "                    idx * (len(series_id_unique) // split_num) :\n",
    "                    (idx + 1) * (len(series_id_unique) // split_num)\n",
    "                ]\n",
    "            series_df_split = series_df[series_df[\"series_id\"].isin(series_id_split)].reset_index(drop=True)\n",
    "            print(f\"series_df_split_{idx} data num : {len(series_df_split)}\")\n",
    "            split_df_path = os.path.join(tmp_file_path, f\"series_df_split_{idx}.parquet\")\n",
    "            series_df_split.to_parquet(split_df_path, index=False)\n",
    "            print(f\"split_df is saved as {split_df_path}\")\n",
    "                \n",
    "    return split_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57c7ddcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T01:52:09.453746Z",
     "iopub.status.busy": "2023-11-12T01:52:09.453501Z",
     "iopub.status.idle": "2023-11-12T01:52:09.473358Z",
     "shell.execute_reply": "2023-11-12T01:52:09.472692Z"
    },
    "papermill": {
     "duration": 0.02776,
     "end_time": "2023-11-12T01:52:09.475212",
     "exception": false,
     "start_time": "2023-11-12T01:52:09.447452",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(CFG, model, infer_loader):\n",
    "    model.eval()\n",
    "\n",
    "    infer_predictions = {\"class_preds\": np.empty(0)}\n",
    "    infer_input_info = {\"series_date_key\": [], \"start_step\": [], \"end_step\": []}\n",
    "\n",
    "    for inputs, input_info_dict in infer_loader:\n",
    "        inputs = inputs.to(CFG.device, non_blocking=True).float()\n",
    "        with torch.no_grad():\n",
    "            preds = model(inputs)\n",
    "\n",
    "        infer_predictions = get_valid_values_dict(preds, infer_predictions, mode=\"preds\")\n",
    "        infer_input_info = concat_valid_input_info(infer_input_info, input_info_dict)\n",
    "\n",
    "    del inputs, preds\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return infer_predictions, infer_input_info  \n",
    "\n",
    "\n",
    "def inference(CFG, exp_dir, exp_name, series_df_path, tmp_file_path, split_num=3):\n",
    "    infer_start_time = time.time()\n",
    "    # series_df = pd.read_parquet(series_df_path)\n",
    "    # split_num = split_data(series_df, tmp_file_path, split_num)\n",
    "    # del series_df\n",
    "    # gc.collect()\n",
    "    for idx in range(split_num):\n",
    "        print(\"split idx:\", idx)\n",
    "        series_df = pl.read_parquet(\n",
    "            os.path.join(tmp_file_path, f\"series_df_split_{idx}.parquet\")\n",
    "        )\n",
    "        if len(series_df)==0:\n",
    "            sub_df_split = pd.DataFrame({ \"series_id\":[],\n",
    "                                          \"step\":[],\n",
    "                                          \"event\":[],\n",
    "                                          \"score\":[]\n",
    "                                        })\n",
    "            sub_df_split_path = os.path.join(tmp_file_path, f\"sub_df_split_{idx}.csv\")\n",
    "            sub_df_split.to_csv(sub_df_split_path, index=False)\n",
    "            continue\n",
    "        series_df = pl_datetime_preprocess(series_df)\n",
    "        series_df = series_df.to_pandas()\n",
    "        series_df = preprocess_input(series_df)\n",
    "        series_df = set_seriesdatekey(series_df)\n",
    "        series_df = label_encode_series_date_key(series_df)\n",
    "        key_df = series_df[[\"series_date_key\", \"series_date_key_str\"]].drop_duplicates()\n",
    "        key_df = key_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "        key_df[\"series_id\"], key_df[\"date\"] = key_df[\"series_date_key_str\"].str.split(\"_\", expand=True)\n",
    "        key_df = key_df.drop(columns=[\"series_date_key_str\"], axis=1)\n",
    "\n",
    "        pred_df = series_df[[\"series_id\", \"series_date_key\", \"step\", \"second\", \"minute\"]].copy()\n",
    "        for fold in CFG.folds:\n",
    "            print(f\"-- fold{fold} inference start --\")\n",
    "            # set model & learning fn\n",
    "            model = get_model(CFG)\n",
    "            model_path = os.path.join(exp_dir, exp_name, f\"fold{fold}_best_model.pth\")\n",
    "            print(\"model loading\", model_path)\n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "            model = model.to(CFG.device)\n",
    "            # separate train/valid data\n",
    "            infer_loader = get_loader(CFG, key_df, series_df, mode=\"test\")\n",
    "            infer_preds, infer_input_dict = predict(CFG, model, infer_loader)\n",
    "            print(f\"split[{idx}] fold[{fold}] prediction finished.\")\n",
    "            pred_df = get_pred_df(\n",
    "                infer_input_dict,\n",
    "                infer_preds,\n",
    "                pred_df,\n",
    "                fold,\n",
    "            )\n",
    "            del infer_preds, infer_input_dict, infer_loader, model\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        pred_df[\"class_pred\"] = pred_df[[f\"class_pred_fold{fold}\" for fold in CFG.folds]].mean(axis=1)\n",
    "        pred_df = pred_df.drop(columns=[f\"class_pred_fold{fold}\" for fold in CFG.folds])\n",
    "        pred_df = detect_event_from_downsample_classpred(pred_df)\n",
    "        pred_df.to_csv(os.path.join(tmp_file_path, f\"pred_df_split_{idx}.csv\"))\n",
    "\n",
    "        sub_df_split = make_submission_df(pred_df)\n",
    "        sub_df_split = sub_df_split.drop(\"event_pred\", axis=1)\n",
    "        sub_df_split = sub_df_split.reset_index(drop=True)\n",
    "        print(f\"sub_df_split_{idx} data num : {len(sub_df_split)}\")\n",
    "        sub_df_split_path = os.path.join(tmp_file_path, f\"sub_df_split_{idx}.csv\")\n",
    "        sub_df_split.to_csv(sub_df_split_path, index=False)\n",
    "        print(f\"sub_df_split is saved as {sub_df_split_path}\")\n",
    "        del sub_df_split, pred_df, series_df, key_df\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    sub_df = pd.DataFrame()\n",
    "    for idx in range(split_num):\n",
    "        if idx==0:\n",
    "            sub_df = pd.read_csv(os.path.join(tmp_file_path, f\"sub_df_split_{idx}.csv\"))\n",
    "        else:\n",
    "            sub_df_tmp = pd.read_csv(os.path.join(tmp_file_path, f\"sub_df_split_{idx}.csv\"))\n",
    "            if len(sub_df_tmp) > 0:\n",
    "                sub_df = pd.concat([sub_df, sub_df_tmp], axis=0)       \n",
    "            del sub_df_tmp\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    sub_df = sub_df.reset_index(drop=True)\n",
    "    print(f\"sub_df data num : {len(sub_df)}\")\n",
    "    return sub_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e048d51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T01:52:09.486421Z",
     "iopub.status.busy": "2023-11-12T01:52:09.486173Z",
     "iopub.status.idle": "2023-11-12T01:52:20.225891Z",
     "shell.execute_reply": "2023-11-12T01:52:20.224800Z"
    },
    "papermill": {
     "duration": 10.747789,
     "end_time": "2023-11-12T01:52:20.228128",
     "exception": false,
     "start_time": "2023-11-12T01:52:09.480339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(T_0=30, T_mult=1, ave_kernel_size=301, batch_size=64, class_loss_weight=1.0, class_output_channels=1, competition_dir='/kaggle/input/child-mind-institute-detect-sleep-states', competition_name='dss', device='cuda', embedding_base_channels=16, eta_min=1e-09, event_df='/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv', event_loss_weight=1.0, event_output_channels=2, exp_category='earlysave', exp_dir='/kaggle/working/exp020_dense_chh_skffold_epoch30', exp_name='exp020_dense_chh_skffold_epoch30', folds=[0, 1, 2, 3, 4], group_key='series_id', input_channels=6, input_dir='/kaggle/input', key_df='/kaggle/input/datakey_unique_non_null.csv', logger_path='/kaggle/working/exp020_dense_chh_skffold_epoch30/train.log', lr=0.001, maxpool_kernel_size=11, model_type='input_target_downsample_dense', n_epoch=30, n_folds=5, num_workers=2, output_channels=2, output_dir='/kaggle/working', print_freq=50, pseudo_weight_exp='exp003', seed=42, series_df='/kaggle/input/targetdownsample_train_series_skffold.parquet', train_mode='train', user_name='taro', wandb_available=True, weight_decay=1e-06)\n",
      "--\n",
      "infer start\n",
      "split idx: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get anglez and enmo rolling mean and std\n",
      "-- fold0 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold0_best_model.pth\n",
      "split[0] fold[0] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold1 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold1_best_model.pth\n",
      "split[0] fold[1] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold2 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold2_best_model.pth\n",
      "split[0] fold[2] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold3 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold3_best_model.pth\n",
      "split[0] fold[3] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold4 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold4_best_model.pth\n",
      "split[0] fold[4] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "sub_df_split_0 data num : 10266\n",
      "sub_df_split is saved as /kaggle/working/tmp/sub_df_split_0.csv\n",
      "split idx: 1\n",
      "get anglez and enmo rolling mean and std\n",
      "-- fold0 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold0_best_model.pth\n",
      "split[1] fold[0] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold1 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold1_best_model.pth\n",
      "split[1] fold[1] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold2 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold2_best_model.pth\n",
      "split[1] fold[2] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold3 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold3_best_model.pth\n",
      "split[1] fold[3] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold4 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold4_best_model.pth\n",
      "split[1] fold[4] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "sub_df_split_1 data num : 8937\n",
      "sub_df_split is saved as /kaggle/working/tmp/sub_df_split_1.csv\n",
      "split idx: 2\n",
      "get anglez and enmo rolling mean and std\n",
      "-- fold0 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold0_best_model.pth\n",
      "split[2] fold[0] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold1 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold1_best_model.pth\n",
      "split[2] fold[1] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold2 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold2_best_model.pth\n",
      "split[2] fold[2] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold3 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold3_best_model.pth\n",
      "split[2] fold[3] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold4 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold4_best_model.pth\n",
      "split[2] fold[4] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "sub_df_split_2 data num : 8829\n",
      "sub_df_split is saved as /kaggle/working/tmp/sub_df_split_2.csv\n",
      "split idx: 3\n",
      "get anglez and enmo rolling mean and std\n",
      "-- fold0 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold0_best_model.pth\n",
      "split[3] fold[0] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold1 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold1_best_model.pth\n",
      "split[3] fold[1] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold2 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold2_best_model.pth\n",
      "split[3] fold[2] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold3 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold3_best_model.pth\n",
      "split[3] fold[3] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold4 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold4_best_model.pth\n",
      "split[3] fold[4] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "sub_df_split_3 data num : 8332\n",
      "sub_df_split is saved as /kaggle/working/tmp/sub_df_split_3.csv\n",
      "split idx: 4\n",
      "get anglez and enmo rolling mean and std\n",
      "-- fold0 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold0_best_model.pth\n",
      "split[4] fold[0] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.07 min\n",
      "-- fold1 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold1_best_model.pth\n",
      "split[4] fold[1] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.07 min\n",
      "-- fold2 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold2_best_model.pth\n",
      "split[4] fold[2] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.07 min\n",
      "-- fold3 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold3_best_model.pth\n",
      "split[4] fold[3] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.07 min\n",
      "-- fold4 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold4_best_model.pth\n",
      "split[4] fold[4] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.07 min\n",
      "sub_df_split_4 data num : 9022\n",
      "sub_df_split is saved as /kaggle/working/tmp/sub_df_split_4.csv\n",
      "split idx: 5\n",
      "get anglez and enmo rolling mean and std\n",
      "-- fold0 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold0_best_model.pth\n",
      "split[5] fold[0] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold1 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold1_best_model.pth\n",
      "split[5] fold[1] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold2 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold2_best_model.pth\n",
      "split[5] fold[2] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold3 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold3_best_model.pth\n",
      "split[5] fold[3] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold4 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold4_best_model.pth\n",
      "split[5] fold[4] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "sub_df_split_5 data num : 9543\n",
      "sub_df_split is saved as /kaggle/working/tmp/sub_df_split_5.csv\n",
      "split idx: 6\n",
      "get anglez and enmo rolling mean and std\n",
      "-- fold0 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold0_best_model.pth\n",
      "split[6] fold[0] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold1 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold1_best_model.pth\n",
      "split[6] fold[1] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold2 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold2_best_model.pth\n",
      "split[6] fold[2] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold3 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold3_best_model.pth\n",
      "split[6] fold[3] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold4 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold4_best_model.pth\n",
      "split[6] fold[4] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "sub_df_split_6 data num : 11381\n",
      "sub_df_split is saved as /kaggle/working/tmp/sub_df_split_6.csv\n",
      "split idx: 7\n",
      "get anglez and enmo rolling mean and std\n",
      "-- fold0 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold0_best_model.pth\n",
      "split[7] fold[0] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold1 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold1_best_model.pth\n",
      "split[7] fold[1] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold2 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold2_best_model.pth\n",
      "split[7] fold[2] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold3 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold3_best_model.pth\n",
      "split[7] fold[3] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold4 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold4_best_model.pth\n",
      "split[7] fold[4] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "sub_df_split_7 data num : 9846\n",
      "sub_df_split is saved as /kaggle/working/tmp/sub_df_split_7.csv\n",
      "split idx: 8\n",
      "get anglez and enmo rolling mean and std\n",
      "-- fold0 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold0_best_model.pth\n",
      "split[8] fold[0] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.07 min\n",
      "-- fold1 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold1_best_model.pth\n",
      "split[8] fold[1] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.07 min\n",
      "-- fold2 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold2_best_model.pth\n",
      "split[8] fold[2] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.07 min\n",
      "-- fold3 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold3_best_model.pth\n",
      "split[8] fold[3] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.07 min\n",
      "-- fold4 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold4_best_model.pth\n",
      "split[8] fold[4] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.07 min\n",
      "sub_df_split_8 data num : 9885\n",
      "sub_df_split is saved as /kaggle/working/tmp/sub_df_split_8.csv\n",
      "split idx: 9\n",
      "get anglez and enmo rolling mean and std\n",
      "-- fold0 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold0_best_model.pth\n",
      "split[9] fold[0] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.05 min\n",
      " >> oof_df created. elapsed time: 0.08 min\n",
      "-- fold1 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold1_best_model.pth\n",
      "split[9] fold[1] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.05 min\n",
      " >> oof_df created. elapsed time: 0.08 min\n",
      "-- fold2 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold2_best_model.pth\n",
      "split[9] fold[2] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.05 min\n",
      " >> oof_df created. elapsed time: 0.08 min\n",
      "-- fold3 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold3_best_model.pth\n",
      "split[9] fold[3] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.05 min\n",
      " >> oof_df created. elapsed time: 0.08 min\n",
      "-- fold4 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold4_best_model.pth\n",
      "split[9] fold[4] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.05 min\n",
      " >> oof_df created. elapsed time: 0.08 min\n",
      "sub_df_split_9 data num : 13242\n",
      "sub_df_split is saved as /kaggle/working/tmp/sub_df_split_9.csv\n",
      "sub_df data num : 99283\n"
     ]
    }
   ],
   "source": [
    "config = yaml.load(open(config_path, \"r\"), Loader=yaml.SafeLoader)\n",
    "config = argparse.Namespace(**config)\n",
    "print(config)\n",
    "seed_everything(config.seed)\n",
    "print(\"--\")\n",
    "print(\"infer start\")\n",
    "sub_df = inference(config, exp_dir, exp_name, series_df_path, tmp_file_path, split_num=dataframe_split_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46a75ed0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T01:52:21.256881Z",
     "iopub.status.busy": "2023-11-12T01:52:21.256525Z",
     "iopub.status.idle": "2023-11-12T01:52:21.282150Z",
     "shell.execute_reply": "2023-11-12T01:52:21.281251Z"
    },
    "papermill": {
     "duration": 0.035219,
     "end_time": "2023-11-12T01:52:21.284476",
     "exception": false,
     "start_time": "2023-11-12T01:52:21.249257",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>event</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>0</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.047167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>96</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.019387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>144</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.024401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>252</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.015829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>444</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.033743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99278</th>\n",
       "      <td>99278</td>\n",
       "      <td>fe90110788d2</td>\n",
       "      <td>589272</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.013174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99279</th>\n",
       "      <td>99279</td>\n",
       "      <td>fe90110788d2</td>\n",
       "      <td>589344</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99280</th>\n",
       "      <td>99280</td>\n",
       "      <td>fe90110788d2</td>\n",
       "      <td>591576</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.034129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99281</th>\n",
       "      <td>99281</td>\n",
       "      <td>fe90110788d2</td>\n",
       "      <td>591720</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.012993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99282</th>\n",
       "      <td>99282</td>\n",
       "      <td>fe90110788d2</td>\n",
       "      <td>592272</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.017481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99283 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_id     series_id    step   event     score\n",
       "0           0  038441c925bb       0  wakeup  0.047167\n",
       "1           1  038441c925bb      96  wakeup  0.019387\n",
       "2           2  038441c925bb     144  wakeup  0.024401\n",
       "3           3  038441c925bb     252  wakeup  0.015829\n",
       "4           4  038441c925bb     444  wakeup  0.033743\n",
       "...       ...           ...     ...     ...       ...\n",
       "99278   99278  fe90110788d2  589272   onset  0.013174\n",
       "99279   99279  fe90110788d2  589344  wakeup  0.015000\n",
       "99280   99280  fe90110788d2  591576   onset  0.034129\n",
       "99281   99281  fe90110788d2  591720   onset  0.012993\n",
       "99282   99282  fe90110788d2  592272  wakeup  0.017481\n",
       "\n",
       "[99283 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_df[\"row_id\"] = range(len(sub_df))\n",
    "sub_df = sub_df[[\"row_id\", \"series_id\", \"step\", \"event\", \"score\"]]\n",
    "if len(sub_df) == 0:\n",
    "    sub_df = pd.read_csv(\"/kaggle/input/child-mind-institute-detect-sleep-states/sample_submission.csv\")\n",
    "sub_df = sub_df.sort_values([\"series_id\", \"step\"]).reset_index(drop=True)\n",
    "sub_df[\"row_id\"] = range(len(sub_df))\n",
    "sub_df.to_csv(\"submission.csv\", index=False)\n",
    "display(sub_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82e18419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df[\"series_id\"].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "610ad295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-12T01:52:21.298417Z",
     "iopub.status.busy": "2023-11-12T01:52:21.298131Z",
     "iopub.status.idle": "2023-11-12T01:52:21.302043Z",
     "shell.execute_reply": "2023-11-12T01:52:21.301187Z"
    },
    "papermill": {
     "duration": 0.013322,
     "end_time": "2023-11-12T01:52:21.304113",
     "exception": false,
     "start_time": "2023-11-12T01:52:21.290791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277\n",
      "0.7417883515684862\n"
     ]
    }
   ],
   "source": [
    "event_df = pd.read_csv(\"/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv\")\n",
    "print(event_df[\"series_id\"].nunique())\n",
    "event_df = event_df.dropna()\n",
    "event_df = event_df[event_df[\"series_id\"].isin(sub_df[\"series_id\"].unique())]\n",
    "from dss_metrics import score\n",
    "\n",
    "print(score(event_df, sub_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb3f5ed",
   "metadata": {
    "papermill": {
     "duration": 0.0059,
     "end_time": "2023-11-12T01:52:21.316040",
     "exception": false,
     "start_time": "2023-11-12T01:52:21.310140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4c5133",
   "metadata": {
    "papermill": {
     "duration": 0.005933,
     "end_time": "2023-11-12T01:52:21.328140",
     "exception": false,
     "start_time": "2023-11-12T01:52:21.322207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23.366533,
   "end_time": "2023-11-12T01:52:23.258262",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-12T01:51:59.891729",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
