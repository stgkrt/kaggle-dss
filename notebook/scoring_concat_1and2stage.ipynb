{"cells":[{"cell_type":"markdown","metadata":{},"source":["# check eventdet oof df"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-09-20T12:42:51.678091Z","iopub.status.busy":"2023-09-20T12:42:51.677683Z","iopub.status.idle":"2023-09-20T12:43:00.424827Z","shell.execute_reply":"2023-09-20T12:43:00.423819Z","shell.execute_reply.started":"2023-09-20T12:42:51.678056Z"},"trusted":true},"outputs":[],"source":["import os\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', 500)"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>series_id</th>\n","      <th>night</th>\n","      <th>event</th>\n","      <th>step</th>\n","      <th>timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>038441c925bb</td>\n","      <td>1</td>\n","      <td>onset</td>\n","      <td>4992.0</td>\n","      <td>2018-08-14T22:26:00-0400</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>038441c925bb</td>\n","      <td>1</td>\n","      <td>wakeup</td>\n","      <td>10932.0</td>\n","      <td>2018-08-15T06:41:00-0400</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>038441c925bb</td>\n","      <td>2</td>\n","      <td>onset</td>\n","      <td>20244.0</td>\n","      <td>2018-08-15T19:37:00-0400</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>038441c925bb</td>\n","      <td>2</td>\n","      <td>wakeup</td>\n","      <td>27492.0</td>\n","      <td>2018-08-16T05:41:00-0400</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>038441c925bb</td>\n","      <td>3</td>\n","      <td>onset</td>\n","      <td>39996.0</td>\n","      <td>2018-08-16T23:03:00-0400</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      series_id  night   event     step                 timestamp\n","0  038441c925bb      1   onset   4992.0  2018-08-14T22:26:00-0400\n","1  038441c925bb      1  wakeup  10932.0  2018-08-15T06:41:00-0400\n","2  038441c925bb      2   onset  20244.0  2018-08-15T19:37:00-0400\n","3  038441c925bb      2  wakeup  27492.0  2018-08-16T05:41:00-0400\n","4  038441c925bb      3   onset  39996.0  2018-08-16T23:03:00-0400"]},"metadata":{},"output_type":"display_data"}],"source":["train_event_df = pd.read_csv(\"/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv\")\n","# train_event_df = train_event_df[train_event_df[\"series_id\"].isin(oof_df[\"series_id\"].unique())].copy()\n","train_event_df = train_event_df.reset_index(drop=True)\n","display(train_event_df.head())"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["import sys\n","sys.path.append(\"/kaggle/src/dss_utils\")\n","\n","from dss_metrics import score"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["event_df = train_event_df[train_event_df[\"step\"].notnull()].copy()"]},{"cell_type":"markdown","metadata":{},"source":["# 1st stage"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["fold_num = 1"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["load oof df\n","fold 0\n"]}],"source":["output_dir = os.path.join(\"/kaggle\", \"working\", \"_oof\")\n","exp_name = \"exp008_meanstd_nonavepool\"\n","print(\"load oof df\")\n","oof_df = pd.DataFrame()\n","for i in range(fold_num):\n","    print(\"fold\", i)\n","    df = pd.read_parquet(os.path.join(output_dir, exp_name, f\"oof_df_fold{i}.parquet\"))\n","    for col in df.columns:\n","        # 64bit float -> 16bit float\n","        if df[col].dtype == np.float64:\n","            df[col] = df[col].astype(np.float16)\n","        # 64bit int -> 16bit int\n","        elif df[col].dtype == np.int64:\n","            df[col] = df[col].astype(np.int16)\n","\n","    oof_df = pd.concat([oof_df, df], axis=0)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# postprocess_fn\n","# series_idでgroupbyして、class_predに対して対象の列のデータから前のN個の列までのデータの平均をとる\n","import torch\n","import torch.nn as nn\n","\n","# 1step 0.5secで30minなら60*30=1800step\n","def postprocess_fn(df, N=1800, maxpool_kernel_size=101, maxpool_stride=1):\n","    df = df.copy()\n","    df[\"class_pred_beforemean\"] = df.groupby(\"series_id\")[\"class_pred\"].apply(lambda x: x.rolling(N, min_periods=1).mean())\n","    df[\"class_pred_aftermean\"] = df.groupby(\"series_id\")[\"class_pred\"].apply(lambda x: x[::-1].rolling(N, min_periods=1).mean()[::-1])\n","    df[\"event_pred\"] = df[\"class_pred_beforemean\"] - df[\"class_pred_aftermean\"]\n","\n","    # 入力サイズと出力サイズが一致するようにpaddingを調整\n","    maxpool_padding = int((maxpool_kernel_size - maxpool_stride) / 2)\n","    # maxpoolしてピーク検出\n","    max_pooling = nn.MaxPool1d(maxpool_kernel_size, stride=maxpool_stride, padding=maxpool_padding)\n","    event_pred = df[\"event_pred\"].values\n","    event_pred = torch.tensor(event_pred).unsqueeze(0)\n","    pooled_event_pred = max_pooling(np.abs(event_pred)).squeeze(0).numpy()\n","    event_pred = event_pred.squeeze(0).numpy()\n","    # peakのところだけ残すmaskを作成\n","    peak_event_pred_mask = np.where(pooled_event_pred == np.abs(event_pred), 1, 0)\n","    peak_event_pred = event_pred * peak_event_pred_mask\n","    df[\"event_pred\"] = peak_event_pred\n","    df = df.drop([\"class_pred_beforemean\", \"class_pred_aftermean\"], axis=1)\n","    return df\n","\n","\n","def make_submission_df(df, threshold=0.1):\n","    df = df[[\"series_id\", \"step\", \"event_pred\"]].copy()\n","    # thresholdより大きいときは1,-thresholdより小さいときは-1,それ以外は0\n","    df[\"event\"] = df[\"event_pred\"].apply(lambda x: 1 if x > threshold else -1 if x < -threshold else 0)\n","    df = df[df[\"event\"] != 0].copy()\n","    df[\"event\"] = df[\"event\"].replace({1: \"wakeup\", -1: \"onset\"})\n","    df[\"score\"] = df[\"event_pred\"].apply(lambda x: np.clip(np.abs(x), 0.0, 1.0))\n","    return df\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.6534456351810006\n"]}],"source":["df = postprocess_fn(oof_df, N=301, maxpool_kernel_size=61)\n","sub_df = make_submission_df(df, threshold=0.01)\n","event_ = event_df[event_df[\"series_id\"].isin(oof_df[\"series_id\"].unique())].copy()\n","print(score(event_, sub_df))"]},{"cell_type":"markdown","metadata":{},"source":["# 2nd stage"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["load oof df\n","fold 0\n"]}],"source":["output_dir = os.path.join(\"/kaggle\", \"working\", \"_oof\")\n","# exp_name = \"event_det_debug\"\n","exp_name = \"debug_secondstg\"\n","print(\"load oof df\")\n","oof_df = pd.DataFrame()\n","# for i in range(5):\n","for i in range(fold_num):\n","    print(\"fold\", i)\n","    df = pd.read_parquet(os.path.join(output_dir, exp_name, f\"oof_df_fold{i}.parquet\"))\n","    for col in df.columns:\n","        # 64bit float -> 16bit float\n","        if df[col].dtype == np.float64:\n","            df[col] = df[col].astype(np.float16)\n","        # 64bit int -> 16bit int\n","        elif df[col].dtype == np.int64:\n","            df[col] = df[col].astype(np.int16)\n","\n","    oof_df = pd.concat([oof_df, df], axis=0)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["Index(['series_id', 'step', 'anglez', 'enmo', 'event', 'event_onset',\n","       'event_wakeup', 'date', 'series_date_key', 'series_date_key_str',\n","       'fold', 'class_pred', 'event_pred', 'event_target', 'onset_pred',\n","       'wakeup_pred', 'onset_target', 'wakeup_target'],\n","      dtype='object')"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["oof_df.columns"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["oof_df[\"step\"] = oof_df[\"step\"].astype(np.float64)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","def make_submission_from_eventdf(df, threshold=0.1):\n","    df = df[[\"series_id\", \"step\", \"onset_pred\", \"wakeup_pred\"]].copy()\n","    df[\"step\"] = df[\"step\"].astype(np.float64)\n","    max_pool = nn.MaxPool1d(11, stride=1, padding=5)\n","    onset_pred = max_pool(torch.tensor(df[\"onset_pred\"].values).unsqueeze(0)).squeeze(0).numpy()\n","    wakeup_pred = max_pool(torch.tensor(df[\"wakeup_pred\"].values).unsqueeze(0)).squeeze(0).numpy()\n","    peak_mask = (onset_pred == df[\"onset_pred\"].values)\n","    df[\"onset_pred\"] = peak_mask * df[\"onset_pred\"].values\n","    peak_mask = (wakeup_pred == df[\"wakeup_pred\"].values)\n","    df[\"wakeup_pred\"] = peak_mask * df[\"wakeup_pred\"].values    \n","    # onset_predが大きい場合-onset_predの値を入力し、wakeup_predが大きい場合wakeup_predの値を入力する\n","    df[\"event_pred\"] = np.where(\n","        df[\"onset_pred\"].values > df[\"wakeup_pred\"].values,\n","        -df[\"onset_pred\"].values,\n","        df[\"wakeup_pred\"].values,\n","    )\n","    # event_predがthreshold以上の場合、wakeup_predが大きい場合はwakeup、onset_predが大きい場合はonsetとする\n","    df[\"event_score\"] = df[\"event_pred\"].apply(\n","        lambda x: 1 if x > threshold else -1 if x < -threshold else 0\n","    )\n","    df = df[df[\"event_score\"] != 0].copy()\n","    df[\"event\"] = df[\"event_score\"].replace({1: \"wakeup\", -1: \"onset\"})\n","    df[\"score\"] = df[\"event_pred\"].apply(lambda x: np.clip(np.abs(x), 0.0, 1.0))\n","    df = df.drop([\"event_pred\", \"onset_pred\", \"wakeup_pred\", \"event_score\"], axis=1)\n","    return df"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["sub_df_2nd_stage = make_submission_from_eventdf(oof_df, threshold=0.1)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["event_series_df = event_df[event_df[\"series_id\"].isin(oof_df[\"series_id\"].unique())].copy()"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["0.2609323275555059"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["score(event_series_df, sub_df_2nd_stage)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["sub_df_1an2_stg = pd.concat([sub_df, sub_df_2nd_stage], axis=0)\n","event_ = event_df[event_df[\"series_id\"].isin(oof_df[\"series_id\"].unique())].copy()"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["0.6534456351810006"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["score(event_, sub_df_1an2_stg)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
