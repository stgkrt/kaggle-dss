{"cells":[{"cell_type":"markdown","metadata":{},"source":["# check oof df"]},{"cell_type":"code","execution_count":17,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-09-20T12:42:51.678091Z","iopub.status.busy":"2023-09-20T12:42:51.677683Z","iopub.status.idle":"2023-09-20T12:43:00.424827Z","shell.execute_reply":"2023-09-20T12:43:00.423819Z","shell.execute_reply.started":"2023-09-20T12:42:51.678056Z"},"trusted":true},"outputs":[],"source":["import os\n","\n","import numpy as np\n","import pandas as pd\n","from pandarallel import pandarallel\n","import matplotlib.pyplot as plt\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', 500)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["fold 0\n","fold 1\n","fold 2\n","fold 3\n","fold 4\n"]}],"source":["output_dir = os.path.join(\"/kaggle\", \"working\", \"_oof\")\n","# exp_name = \"baseline000\"\n","# exp_name = \"baseline000_1697037446.0796616\"\n","# exp_name = \"baseline_alldata_allfold_000\"\n","exp_name = \"exp000\"\n","# oof_df_path = os.path.join(output_dir, exp_name,\"oof_df.parquet\")\n","# oof_df = pd.read_parquet(oof_df_path)\n","for i in range(5):\n","    print(\"fold\", i)\n","    oof_df = pd.concat(\n","        [pd.read_parquet(os.path.join(output_dir, exp_name, f\"oof_df_fold{i}.parquet\"))]\n","        ,axis=0\n","    )"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["# postprocess_fn\n","# series_idでgroupbyして、class_predに対して対象の列のデータから前のN個の列までのデータの平均をとる\n","import torch\n","import torch.nn as nn\n","\n","# 1step 0.5secで30minなら60*30=1800step\n","def postprocess_fn(df, N=1800, maxpool_kernel_size=101, maxpool_stride=1):\n","    df = df.copy()\n","    df[\"class_pred_beforemean\"] = df.groupby(\"series_id\")[\"class_pred\"].apply(lambda x: x.rolling(N, min_periods=1).mean())\n","    df[\"class_pred_aftermean\"] = df.groupby(\"series_id\")[\"class_pred\"].apply(lambda x: x[::-1].rolling(N, min_periods=1).mean()[::-1])\n","    df[\"event_pred\"] = df[\"class_pred_beforemean\"] - df[\"class_pred_aftermean\"]\n","\n","    # 入力サイズと出力サイズが一致するようにpaddingを調整\n","    maxpool_padding = int((maxpool_kernel_size - maxpool_stride) / 2)\n","    # maxpoolしてピーク検出\n","    max_pooling = nn.MaxPool1d(maxpool_kernel_size, stride=maxpool_stride, padding=maxpool_padding)\n","    event_pred = df[\"event_pred\"].values\n","    event_pred = torch.tensor(event_pred).unsqueeze(0)\n","    pooled_event_pred = max_pooling(np.abs(event_pred)).squeeze(0).numpy()\n","    event_pred = event_pred.squeeze(0).numpy()\n","    # peakのところだけ残すmaskを作成\n","    peak_event_pred_mask = np.where(pooled_event_pred == np.abs(event_pred), 1, 0)\n","    peak_event_pred = event_pred * peak_event_pred_mask\n","    df[\"event_pred\"] = peak_event_pred\n","    df = df.drop([\"class_pred_beforemean\", \"class_pred_aftermean\"], axis=1)\n","    return df\n","\n","\n","def make_submission_df(df, threshold=0.1):\n","    df = df[[\"series_id\", \"step\", \"event_pred\"]].copy()\n","    # thresholdより大きいときは1,-thresholdより小さいときは-1,それ以外は0\n","    df[\"event\"] = df[\"event_pred\"].apply(lambda x: 1 if x > threshold else -1 if x < -threshold else 0)\n","    df = df[df[\"event\"] != 0].copy()\n","    df[\"event\"] = df[\"event\"].replace({1: \"wakeup\", -1: \"onset\"})\n","    df[\"score\"] = df[\"event_pred\"].apply(lambda x: np.clip(np.abs(x), 0.0, 1.0))\n","    return df\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# df = postprocess_fn(oof_df, N=1200)\n","# sub_df = make_submission_df(df, threshold=0.2)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# data_num = 20000\n","# for _ in range(5):\n","#     random_num = np.random.randint(0, len(df)-data_num)\n","#     print(random_num)\n","#     plt.figure(figsize=(20, 5))\n","#     plt.subplot(3, 1, 1)\n","#     plt.plot(df[\"step\"].iloc[random_num:random_num+data_num], df[\"event_pred\"].iloc[random_num:random_num+data_num], label=\"class_pred\")\n","#     plt.subplot(3, 1, 2)\n","#     plt.plot(df[\"step\"].iloc[random_num:random_num+data_num], df[\"event\"].iloc[random_num:random_num+data_num], label=\"event_pred\")\n","#     plt.subplot(3, 1, 3)\n","#     plt.plot(df[\"step\"].iloc[random_num:random_num+data_num], df[\"class_pred\"].iloc[random_num:random_num+data_num], label=\"class_pred\")\n"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>series_id</th>\n","      <th>night</th>\n","      <th>event</th>\n","      <th>step</th>\n","      <th>timestamp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>038441c925bb</td>\n","      <td>1</td>\n","      <td>onset</td>\n","      <td>4992.0</td>\n","      <td>2018-08-14T22:26:00-0400</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>038441c925bb</td>\n","      <td>1</td>\n","      <td>wakeup</td>\n","      <td>10932.0</td>\n","      <td>2018-08-15T06:41:00-0400</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>038441c925bb</td>\n","      <td>2</td>\n","      <td>onset</td>\n","      <td>20244.0</td>\n","      <td>2018-08-15T19:37:00-0400</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>038441c925bb</td>\n","      <td>2</td>\n","      <td>wakeup</td>\n","      <td>27492.0</td>\n","      <td>2018-08-16T05:41:00-0400</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>038441c925bb</td>\n","      <td>3</td>\n","      <td>onset</td>\n","      <td>39996.0</td>\n","      <td>2018-08-16T23:03:00-0400</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      series_id  night   event     step                 timestamp\n","0  038441c925bb      1   onset   4992.0  2018-08-14T22:26:00-0400\n","1  038441c925bb      1  wakeup  10932.0  2018-08-15T06:41:00-0400\n","2  038441c925bb      2   onset  20244.0  2018-08-15T19:37:00-0400\n","3  038441c925bb      2  wakeup  27492.0  2018-08-16T05:41:00-0400\n","4  038441c925bb      3   onset  39996.0  2018-08-16T23:03:00-0400"]},"metadata":{},"output_type":"display_data"}],"source":["train_event_df = pd.read_csv(\"/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv\")\n","train_event_df = train_event_df[train_event_df[\"series_id\"].isin(oof_df[\"series_id\"].unique())].copy()\n","train_event_df = train_event_df.reset_index(drop=True)\n","display(train_event_df.head())"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["import sys\n","sys.path.append(\"/kaggle/src/dss_utils\")\n","\n","# series_id_column_name = \"series_id\"\n","# time_column_name = \"step\"\n","# event_column_name = \"event\"\n","# score_column_name = \"score\"\n","# use_scoring_intervals = None  # type:ignore\n","\n","\n","# # [1, 3, 5, 7, 10, 13, 15, 20, 25, 30] minute\n","# tolerances = {\n","#     \"onset\": [12, 36, 60, 90, 120, 150, 180, 240, 300, 360],\n","#     \"wakeup\": [12, 36, 60, 90, 120, 150, 180, 240, 300, 360],\n","# }\n","\n","from dss_metrics import score"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["event_df = train_event_df[train_event_df[\"step\"].notnull()].copy()"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[],"source":["average_size = 200\n","max_kernel_size = 101\n","df = postprocess_fn(oof_df, N=average_size, maxpool_kernel_size=max_kernel_size)\n","sub_df = make_submission_df(df, threshold=0.1)"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"data":{"text/plain":["0.6494387768263943"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["score(event_df, sub_df)"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[],"source":["# for average_size in range(101, 151, 201):\n","#     for max_kernel_size in range(11, 101, 10):\n","#         print(\"average_size\", average_size, \"max_kernel_size\", max_kernel_size)\n","#         df = postprocess_fn(oof_df, N=average_size, maxpool_kernel_size=max_kernel_size)\n","#         sub_df = make_submission_df(df, threshold=0.1)\n","#         print(score(event_df, sub_df))"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["# for average_size in [201, 151]:\n","#     for max_kernel_size in range(11, 101, 10):\n","#         print(\"average_size\", average_size, \"max_kernel_size\", max_kernel_size)\n","#         df = postprocess_fn(oof_df, N=average_size, maxpool_kernel_size=max_kernel_size)\n","#         sub_df = make_submission_df(df, threshold=0.1)\n","#         print(score(event_df, sub_df))"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[],"source":["# max_kernel_size = 41\n","# for average_size in range(301, 601, 100):\n","#     print(\"average_size\", average_size, \"max_kernel_size\", max_kernel_size)\n","#     df = postprocess_fn(oof_df, N=average_size, maxpool_kernel_size=max_kernel_size)\n","#     sub_df = make_submission_df(df, threshold=0.1)\n","#     print(score(event_df, sub_df))"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["average_size 201 max_kernel_size 41\n","0.6507715513863849\n","average_size 221 max_kernel_size 41\n","0.6537339796886537\n","average_size 241 max_kernel_size 41\n","0.6561407703011912\n","average_size 261 max_kernel_size 41\n","0.6576799761907189\n","average_size 281 max_kernel_size 41\n","0.6575245455595717\n","average_size 301 max_kernel_size 41\n","0.6577504639656441\n","average_size 321 max_kernel_size 41\n","0.6569745968622127\n","average_size 341 max_kernel_size 41\n","0.6562378869455485\n","average_size 361 max_kernel_size 41\n","0.6552772069687894\n","average_size 381 max_kernel_size 41\n","0.6557543937388506\n"]}],"source":["max_kernel_size = 41\n","for average_size in range(201, 401, 20):\n","    print(\"average_size\", average_size, \"max_kernel_size\", max_kernel_size)\n","    df = postprocess_fn(oof_df, N=average_size, maxpool_kernel_size=max_kernel_size)\n","    sub_df = make_submission_df(df, threshold=0.1)\n","    print(score(event_df, sub_df))"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["average_size 401 max_kernel_size 41\n","0.6550113465426012\n","average_size 501 max_kernel_size 41\n","0.6551176525789024\n","average_size 601 max_kernel_size 41\n","0.6541576011134318\n","average_size 701 max_kernel_size 41\n","0.6542691205014803\n","average_size 801 max_kernel_size 41\n","0.6582780850952523\n","average_size 901 max_kernel_size 41\n","0.6561059229388471\n"]}],"source":["max_kernel_size = 41\n","for average_size in range(401, 1001, 100):\n","    print(\"average_size\", average_size, \"max_kernel_size\", max_kernel_size)\n","    df = postprocess_fn(oof_df, N=average_size, maxpool_kernel_size=max_kernel_size)\n","    sub_df = make_submission_df(df, threshold=0.1)\n","    print(score(event_df, sub_df))"]},{"cell_type":"markdown","metadata":{},"source":["## exp 000\n","average_size 201 max_kernel_size 41\n","0.6507715513863849\n","average_size 221 max_kernel_size 41\n","0.6537339796886537\n","average_size 241 max_kernel_size 41\n","0.6561407703011912\n","average_size 261 max_kernel_size 41\n","0.6576799761907189\n","average_size 281 max_kernel_size 41\n","0.6575245455595717\n","average_size 301 max_kernel_size 41\n","0.6577504639656441\n","average_size 321 max_kernel_size 41\n","0.6569745968622127\n","average_size 341 max_kernel_size 41\n","0.6562378869455485\n","average_size 361 max_kernel_size 41\n","0.6552772069687894\n","average_size 381 max_kernel_size 41\n","0.6557543937388506"]},{"cell_type":"markdown","metadata":{},"source":["# exp001\n","average_size 401 max_kernel_size 41\n","0.6312146268156249\n","average_size 501 max_kernel_size 41\n","0.635633422232492\n","average_size 601 max_kernel_size 41\n","0.6368531157055373\n","average_size 701 max_kernel_size 41\n","0.6369187233473134\n","average_size 801 max_kernel_size 41\n","0.6415632079075928\n","average_size 901 max_kernel_size 41\n","0.6409006872463292"]},{"cell_type":"markdown","metadata":{},"source":["# exp002\n","average_size 201 max_kernel_size 41\n","0.6311561301629709\n","average_size 221 max_kernel_size 41\n","0.6338846022029172\n","average_size 241 max_kernel_size 41\n","0.6339425602342341\n","average_size 261 max_kernel_size 41\n","0.6342376545266758\n","average_size 281 max_kernel_size 41\n","0.6348944831498222\n","average_size 301 max_kernel_size 41\n","0.6343623084738816\n","average_size 321 max_kernel_size 41\n","0.6340311850884977\n","average_size 341 max_kernel_size 41\n","0.6329142802968093\n","average_size 361 max_kernel_size 41\n","0.632642525476107\n","average_size 381 max_kernel_size 41\n","0.6316554793826874"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":4}
