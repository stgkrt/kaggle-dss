{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "298d2a36",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-09T08:31:51.529826Z",
     "iopub.status.busy": "2023-11-09T08:31:51.528970Z",
     "iopub.status.idle": "2023-11-09T08:31:52.466775Z",
     "shell.execute_reply": "2023-11-09T08:31:52.465968Z"
    },
    "papermill": {
     "duration": 0.947821,
     "end_time": "2023-11-09T08:31:52.469202",
     "exception": false,
     "start_time": "2023-11-09T08:31:51.521381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import argparse\n",
    "import yaml\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9f22c8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T08:31:52.482240Z",
     "iopub.status.busy": "2023-11-09T08:31:52.481850Z",
     "iopub.status.idle": "2023-11-09T08:31:56.957069Z",
     "shell.execute_reply": "2023-11-09T08:31:56.956061Z"
    },
    "papermill": {
     "duration": 4.484235,
     "end_time": "2023-11-09T08:31:56.959543",
     "exception": false,
     "start_time": "2023-11-09T08:31:52.475308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"/kaggle/src/exp\")\n",
    "sys.path.append(\"/kaggle/src/data\")\n",
    "sys.path.append(\"/kaggle/src/model\")\n",
    "sys.path.append(\"/kaggle/src/dss_utils\")\n",
    "sys.path.append(\"/kaggle/src/submission\")\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from dss_dataloader import get_loader\n",
    "from dss_model import get_model\n",
    "from training_loop import concat_valid_input_info, get_valid_values_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32a631f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T08:31:56.972825Z",
     "iopub.status.busy": "2023-11-09T08:31:56.972538Z",
     "iopub.status.idle": "2023-11-09T08:31:56.977555Z",
     "shell.execute_reply": "2023-11-09T08:31:56.976685Z"
    },
    "papermill": {
     "duration": 0.013922,
     "end_time": "2023-11-09T08:31:56.979457",
     "exception": false,
     "start_time": "2023-11-09T08:31:56.965535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_dir = \"/kaggle/working\"\n",
    "exp_name = \"exp020_dense_chh_skffold_epoch30\" # exp020_dense_chh_skffold_epoch30からbest modelを保存するようになった\n",
    "# series_df_path = \"/kaggle/input/child-mind-institute-detect-sleep-states/test_series.parquet\"\n",
    "series_df_path = \"/kaggle/input/child-mind-institute-detect-sleep-states/train_series.parquet\"\n",
    "tmp_file_path = \"/kaggle/working/tmp_event\"\n",
    "split_file_path = \"/kaggle/working/tmp\"\n",
    "os.makedirs(tmp_file_path, exist_ok=True)\n",
    "config_path = os.path.join(exp_dir, exp_name, \"config.yaml\")\n",
    "\n",
    "class_pred_roll_mean_num = 9\n",
    "class_pred_maxpool_num = 3\n",
    "\n",
    "dataframe_split_num = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56028df7",
   "metadata": {
    "papermill": {
     "duration": 0.005316,
     "end_time": "2023-11-09T08:31:57.008436",
     "exception": false,
     "start_time": "2023-11-09T08:31:57.003120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e3c71c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T08:31:57.020618Z",
     "iopub.status.busy": "2023-11-09T08:31:57.020344Z",
     "iopub.status.idle": "2023-11-09T08:31:57.034035Z",
     "shell.execute_reply": "2023-11-09T08:31:57.033187Z"
    },
    "papermill": {
     "duration": 0.022302,
     "end_time": "2023-11-09T08:31:57.036156",
     "exception": false,
     "start_time": "2023-11-09T08:31:57.013854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pl_datetime_preprocess(train_series_):\n",
    "    train_series_ = train_series_.with_columns(\n",
    "        pl.col(\"timestamp\").str.to_datetime().dt.replace_time_zone(None))\n",
    "    train_series_ = train_series_.with_columns(\n",
    "        pl.col(\"timestamp\").dt.second().cast(pl.Int32).alias(\"second\"))\n",
    "    train_series_ = train_series_.with_columns(\n",
    "        pl.col(\"timestamp\").dt.minute().cast(pl.Int32).alias(\"minute\"))\n",
    "    train_series_ = train_series_.with_columns(\n",
    "        pl.col(\"timestamp\").dt.date().cast(str).alias(\"date\"))\n",
    "    return train_series_\n",
    "\n",
    "\n",
    "def preprocess_input(train_series_: pd.DataFrame) -> pd.DataFrame:\n",
    "    train_series_ = train_series_.drop(columns=[\"timestamp\"], axis=1)\n",
    "    # anglezとenmoのrolling meanとrolling stdを取る\n",
    "    print(\"get anglez and enmo rolling mean and std\")\n",
    "    for roll_num in [36, 60]:  # 雰囲気で選んだ\n",
    "        train_series_[f\"anglez_mean_{roll_num}\"] = (\n",
    "            train_series_.groupby(\"series_id\")[\"anglez\"].rolling(\n",
    "                roll_num, center=True).mean().reset_index(0, drop=True))\n",
    "        train_series_[f\"enmo_mean_{roll_num}\"] = (\n",
    "            train_series_.groupby(\"series_id\")[\"enmo\"].rolling(\n",
    "                roll_num, center=True).mean().reset_index(0, drop=True))\n",
    "        train_series_[f\"anglez_std_{roll_num}\"] = (\n",
    "            train_series_.groupby(\"series_id\")[\"anglez\"].rolling(\n",
    "                roll_num, center=True).std().reset_index(0, drop=True))\n",
    "        train_series_[f\"enmo_std_{roll_num}\"] = (\n",
    "            train_series_.groupby(\"series_id\")[\"enmo\"].rolling(\n",
    "                roll_num, center=True).std().reset_index(0, drop=True))\n",
    "        train_series_[f\"anglez_mean_{roll_num}\"] = train_series_[\n",
    "            f\"anglez_mean_{roll_num}\"].fillna(0)\n",
    "        train_series_[f\"enmo_mean_{roll_num}\"] = train_series_[\n",
    "            f\"enmo_mean_{roll_num}\"].fillna(0)\n",
    "        train_series_[f\"anglez_std_{roll_num}\"] = train_series_[\n",
    "            f\"anglez_std_{roll_num}\"].fillna(0)\n",
    "        train_series_[f\"enmo_std_{roll_num}\"] = train_series_[\n",
    "            f\"enmo_std_{roll_num}\"].fillna(0)\n",
    "    \n",
    "    return train_series_\n",
    "\n",
    "\n",
    "def set_seriesdatekey(train_series_: pd.DataFrame) -> pd.DataFrame:\n",
    "    train_series_[\"series_date_key\"] = (\n",
    "        train_series_[\"series_id\"].astype(str) + \"_\" + train_series_[\"date\"].astype(str)\n",
    "    )\n",
    "    return train_series_\n",
    "\n",
    "def label_encode_series_date_key(train_series_: pd.DataFrame) -> pd.DataFrame:\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    train_series_[\"series_date_key_str\"] = train_series_[\"series_date_key\"].astype(str)\n",
    "    train_series_[\"series_date_key\"] = le.fit_transform(\n",
    "        train_series_[\"series_date_key_str\"]\n",
    "    )\n",
    "    train_series_[\"series_date_key\"] = train_series_[\"series_date_key\"].astype(\"int64\")\n",
    "    return train_series_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de16678",
   "metadata": {
    "papermill": {
     "duration": 0.005328,
     "end_time": "2023-11-09T08:31:57.047124",
     "exception": false,
     "start_time": "2023-11-09T08:31:57.041796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# post process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a760d45c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T08:31:57.059589Z",
     "iopub.status.busy": "2023-11-09T08:31:57.059283Z",
     "iopub.status.idle": "2023-11-09T08:31:57.075839Z",
     "shell.execute_reply": "2023-11-09T08:31:57.074861Z"
    },
    "papermill": {
     "duration": 0.025098,
     "end_time": "2023-11-09T08:31:57.077692",
     "exception": false,
     "start_time": "2023-11-09T08:31:57.052594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1step 0.5secで30minなら60*30=1800step?\n",
    "# metric的にいっぱい検出してもいい？とりあえず小さめ\n",
    "def detect_event_from_downsample_classpred(CFG, df, N=class_pred_roll_mean_num, maxpool_kernel_size=class_pred_maxpool_num, maxpool_stride=1):\n",
    "    df = df[df[\"second\"] == 0].reset_index(drop=True)\n",
    "    for fold in CFG.folds:\n",
    "        df[\"class_pred_beforemean\"] = df.groupby(\"series_id\")[f\"class_pred_fold{fold}\"].apply(\n",
    "            lambda x: x.rolling(N, min_periods=1).mean()\n",
    "        ).reset_index(drop=True)\n",
    "        df[\"class_pred_aftermean\"] = df.groupby(\"series_id\")[f\"class_pred_fold{fold}\"].apply(\n",
    "            lambda x: x[::-1].rolling(N, min_periods=1).mean()[::-1]\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "        df[f\"event_pred_fold{fold}\"] = df[\"class_pred_beforemean\"] - df[\"class_pred_aftermean\"]\n",
    "        # 入力サイズと出力サイズが一致するようにpaddingを調整\n",
    "        maxpool_padding = int((maxpool_kernel_size - maxpool_stride) / 2)\n",
    "        # maxpoolしてピーク検出\n",
    "        max_pooling = nn.MaxPool1d(maxpool_kernel_size,\n",
    "                                   stride=maxpool_stride,\n",
    "                                   padding=maxpool_padding)\n",
    "        event_pred = df[f\"event_pred_fold{fold}\"].values\n",
    "        event_pred = torch.tensor(event_pred).unsqueeze(0)\n",
    "        pooled_event_pred = max_pooling(np.abs(event_pred)).squeeze(0).numpy()\n",
    "        event_pred = event_pred.squeeze(0).numpy()\n",
    "        # peakのところだけ残すmaskを作成\n",
    "        peak_event_pred_mask = np.where(pooled_event_pred == np.abs(event_pred), 1, 0)\n",
    "        peak_event_pred = event_pred * peak_event_pred_mask\n",
    "        df[f\"event_pred_fold{fold}\"] = peak_event_pred\n",
    "        df[f\"onset_pred_fold{fold}\"] = np.clip(-df[f\"event_pred_fold{fold}\"], 0, 1)\n",
    "        df[f\"wakeup_pred_fold{fold}\"] = np.clip(df[f\"event_pred_fold{fold}\"], 0, 1)\n",
    "        df = df.drop([\"class_pred_beforemean\", \"class_pred_aftermean\"], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_submission_df(df, threshold=0.01):\n",
    "    df = df[[\"series_id\", \"step\", \"event_pred\"]]\n",
    "    # thresholdより大きいときは1,-thresholdより小さいときは-1,それ以外は0\n",
    "    df[\"event\"] = df[\"event_pred\"].apply(\n",
    "        lambda x: 1 if x > threshold else -1 if x < -threshold else 0\n",
    "    )\n",
    "    df = df[df[\"event\"] != 0]\n",
    "    df[\"event\"] = df[\"event\"].replace({1: \"wakeup\", -1: \"onset\"})\n",
    "    df[\"score\"] = df[\"event_pred\"].apply(lambda x: np.clip(np.abs(x), 0.0, 1.0))\n",
    "    df = df.drop(\"event_pred\", axis=1)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba5ee7c",
   "metadata": {
    "papermill": {
     "duration": 0.005493,
     "end_time": "2023-11-09T08:31:57.088776",
     "exception": false,
     "start_time": "2023-11-09T08:31:57.083283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# infer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57da3a6",
   "metadata": {
    "papermill": {
     "duration": 0.005406,
     "end_time": "2023-11-09T08:31:57.099833",
     "exception": false,
     "start_time": "2023-11-09T08:31:57.094427",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## data utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6624b748",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T08:31:57.154013Z",
     "iopub.status.busy": "2023-11-09T08:31:57.153738Z",
     "iopub.status.idle": "2023-11-09T08:31:57.166388Z",
     "shell.execute_reply": "2023-11-09T08:31:57.165712Z"
    },
    "papermill": {
     "duration": 0.021303,
     "end_time": "2023-11-09T08:31:57.168275",
     "exception": false,
     "start_time": "2023-11-09T08:31:57.146972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pred_df(\n",
    "    input_info_dict: dict,\n",
    "    preds_dict: dict,\n",
    "    pred_df: pd.DataFrame,\n",
    "    fold: int,\n",
    ") -> pd.DataFrame:\n",
    "    start_time = time.time()\n",
    "    print(\"creating oof_df\", end=\" ... \")\n",
    "    if \"class_pred\" in pred_df.columns:\n",
    "        pred_df = pred_df.drop([\"class_pred\"], axis=1)\n",
    "    series_date_key_list = []\n",
    "    class_pred_list, steps_list = [],  []\n",
    "\n",
    "    for idx, (series_date_key, start_step, end_step) in enumerate(\n",
    "            zip(\n",
    "                input_info_dict[\"series_date_key\"],\n",
    "                input_info_dict[\"start_step\"],\n",
    "                input_info_dict[\"end_step\"],\n",
    "            )):\n",
    "        if not isinstance(series_date_key, np.int64):\n",
    "            series_date_key = series_date_key.numpy()\n",
    "        # preds targets shape: [batch, ch, data_length]\n",
    "        class_pred = preds_dict[\"class_preds\"][idx]\n",
    "        steps = range(start_step, end_step + 1, 12)\n",
    "        series_date_data_num = len(steps)\n",
    "        if series_date_data_num < len(class_pred[0]):\n",
    "            class_pred = class_pred[0, :series_date_data_num]\n",
    "        elif series_date_data_num > len(class_pred[0]):\n",
    "            padding_num = series_date_data_num - len(class_pred[0])\n",
    "            class_pred = np.concatenate(\n",
    "                [class_pred[0], -1 * np.ones(padding_num)], axis=0)\n",
    "        else:\n",
    "            class_pred = class_pred[0]\n",
    "        if not (len(class_pred) == len(steps)):\n",
    "            print(\"len(class_pred)\", len(class_pred))\n",
    "            print(\"len(steps)\", len(steps))\n",
    "            raise ValueError(\"preds and step length is not same\")\n",
    "        class_pred_list.extend(class_pred)\n",
    "        steps_list.extend(steps)\n",
    "        series_date_key_list.extend([series_date_key] * len(steps))\n",
    "    pred_col_name = f\"class_pred_fold{fold}\"\n",
    "    oof_pred_target_df = pd.DataFrame({\n",
    "        \"series_date_key\": series_date_key_list,\n",
    "        \"step\": steps_list,\n",
    "        pred_col_name: class_pred_list,\n",
    "    })\n",
    "    merge_start_time = time.time()\n",
    "    print(\"merging oof_df\")\n",
    "    oof_pred_target_df[\"series_date_key\"] = oof_pred_target_df[\"series_date_key\"].astype(\"int64\")\n",
    "    pred_df = pd.merge(pred_df,\n",
    "                       oof_pred_target_df,\n",
    "                       on=[\"series_date_key\", \"step\"],\n",
    "                       how=\"left\")\n",
    "    pred_df[pred_col_name] = pred_df[pred_col_name].fillna(0)\n",
    "    merge_elapsed = int(time.time() - merge_start_time) / 60\n",
    "    print(\"merge elapsed time: {:.2f} min\".format(merge_elapsed))\n",
    "    elapsed = int(time.time() - start_time) / 60\n",
    "    print(f\" >> oof_df created. elapsed time: {elapsed:.2f} min\")\n",
    "    return pred_df        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa541f1",
   "metadata": {
    "papermill": {
     "duration": 0.005429,
     "end_time": "2023-11-09T08:31:57.179259",
     "exception": false,
     "start_time": "2023-11-09T08:31:57.173830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## pred & infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "913b1299",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T08:31:57.191422Z",
     "iopub.status.busy": "2023-11-09T08:31:57.191165Z",
     "iopub.status.idle": "2023-11-09T08:31:57.213905Z",
     "shell.execute_reply": "2023-11-09T08:31:57.213230Z"
    },
    "papermill": {
     "duration": 0.031091,
     "end_time": "2023-11-09T08:31:57.215800",
     "exception": false,
     "start_time": "2023-11-09T08:31:57.184709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(CFG, model, infer_loader):\n",
    "    model.eval()\n",
    "\n",
    "    infer_predictions = {\"class_preds\": np.empty(0)}\n",
    "    infer_input_info = {\"series_date_key\": [], \"start_step\": [], \"end_step\": []}\n",
    "\n",
    "    for _, (inputs, input_info_dict) in enumerate(infer_loader):\n",
    "        inputs = inputs.to(CFG.device, non_blocking=True).float()\n",
    "        with torch.no_grad():\n",
    "            preds = model(inputs)\n",
    "\n",
    "        infer_predictions = get_valid_values_dict(\n",
    "            preds, infer_predictions, mode=\"preds\"\n",
    "        )\n",
    "        infer_input_info = concat_valid_input_info(infer_input_info, input_info_dict)\n",
    "\n",
    "    del inputs, preds\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    return infer_predictions, infer_input_info\n",
    "\n",
    "\n",
    "def infer_onedf(CFG, series_df, split_idx):\n",
    "    series_df = pl_datetime_preprocess(series_df)\n",
    "    series_df = series_df.to_pandas()\n",
    "    series_df = preprocess_input(series_df)\n",
    "    series_df = set_seriesdatekey(series_df)\n",
    "    series_df = label_encode_series_date_key(series_df)\n",
    "    key_df = series_df[[\"series_date_key\", \"series_date_key_str\"]].drop_duplicates()\n",
    "    key_df = key_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    key_df[\"series_id\"], key_df[\"date\"] = key_df[\"series_date_key_str\"].str.split(\"_\", expand=True)\n",
    "    key_df = key_df.drop(columns=[\"series_date_key_str\"], axis=1)\n",
    "\n",
    "    pred_df = series_df[[\"series_id\", \"series_date_key\", \"step\", \"second\"]].copy()\n",
    "    for fold in CFG.folds:\n",
    "        print(f\"-- fold{fold} inference start --\")\n",
    "        # set model & learning fn\n",
    "        model = get_model(CFG)\n",
    "        model_path = os.path.join(exp_dir, exp_name, f\"fold{fold}_model.pth\")\n",
    "        print(\"model loading\", model_path)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model = model.to(CFG.device)\n",
    "        # separate train/valid data\n",
    "        infer_loader = get_loader(CFG, key_df, series_df, mode=\"test\")\n",
    "        infer_preds, infer_input_dict = predict(CFG, model, infer_loader)\n",
    "        print(f\"split[{split_idx}] fold[{fold}] prediction finished.\")\n",
    "        pred_df = get_pred_df(\n",
    "            infer_input_dict,\n",
    "            infer_preds,\n",
    "            pred_df,\n",
    "            fold,\n",
    "        )\n",
    "        del infer_preds, infer_input_dict, infer_loader, model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # meanでいいの？maxにしてみる？\n",
    "    pred_df = detect_event_from_downsample_classpred(CFG, pred_df)\n",
    "    # mean? max?\n",
    "    pred_df[\"event_pred\"] = pred_df[[f\"event_pred_fold{fold}\" for fold in CFG.folds]].mean(axis=1)\n",
    "    # pred_df[\"event_pred\"] = pred_df[[f\"event_pred_fold{fold}\" for fold in CFG.folds]].max(axis=1)\n",
    "    pred_df = pred_df.drop(columns=[f\"event_pred_fold{fold}\" for fold in CFG.folds])\n",
    "#     display(pred_df)\n",
    "    pred_df.to_csv(os.path.join(tmp_file_path, f\"pred_df_split_{split_idx}.csv\"))\n",
    "    return pred_df\n",
    "    \n",
    "def inference(\n",
    "    CFG, exp_dir, exp_name, series_df_path, tmp_file_path, split_num=3\n",
    "):\n",
    "    infer_start_time = time.time()\n",
    "    infer_data_num = -1\n",
    "    for idx in range(split_num):\n",
    "        print(\"split idx:\", idx)\n",
    "        series_df = pl.read_parquet(\n",
    "            os.path.join(split_file_path, f\"series_df_split_{idx}.parquet\")\n",
    "        )\n",
    "        # testが見えているものを読み込んだときでもむりやり動かす\n",
    "        if infer_data_num==450:\n",
    "            series_df = pl.read_parquet(series_df_path)\n",
    "            pred_df = infer_onedf(CFG, series_df, idx)\n",
    "            sub_df_split = make_submission_df(pred_df)\n",
    "            sub_df_split_path = os.path.join(tmp_file_path, f\"sub_df.csv\")\n",
    "            sub_df_split.to_csv(sub_df_split_path, index=False)\n",
    "            break\n",
    "        pred_df = infer_onedf(CFG, series_df, idx)\n",
    "        \n",
    "        sub_df_split = make_submission_df(pred_df)\n",
    "        sub_df_split_path = os.path.join(tmp_file_path, f\"sub_df_split_{idx}.csv\")\n",
    "        sub_df_split.to_csv(sub_df_split_path, index=False)\n",
    "        print(f\"sub_df_split is saved as {sub_df_split_path}\")\n",
    "        del sub_df_split, pred_df, series_df\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # testが見えているものを読み込んだときでもむりやり動かす\n",
    "    if infer_data_num==450:\n",
    "        sub_df = pd.read_csv(sub_df_split_path)\n",
    "        sub_df_tmp = None\n",
    "    else:\n",
    "        sub_df = pd.DataFrame()\n",
    "        for idx in range(split_num):\n",
    "            if idx==0:\n",
    "                sub_df = pd.read_csv(os.path.join(tmp_file_path, f\"sub_df_split_{idx}.csv\"))\n",
    "            else:\n",
    "                sub_df_tmp = pd.read_csv(os.path.join(tmp_file_path, f\"sub_df_split_{idx}.csv\"))\n",
    "                if len(sub_df_tmp) > 0:\n",
    "                    sub_df = pd.concat([sub_df, sub_df_tmp], axis=0)       \n",
    "\n",
    "    del sub_df_tmp\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    sub_df = sub_df.reset_index(drop=True)\n",
    "    print(f\"sub_df data num : {len(sub_df)}\")\n",
    "    return sub_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5e1603f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T08:31:57.228244Z",
     "iopub.status.busy": "2023-11-09T08:31:57.227992Z",
     "iopub.status.idle": "2023-11-09T08:38:15.029540Z",
     "shell.execute_reply": "2023-11-09T08:38:15.028373Z"
    },
    "papermill": {
     "duration": 377.810464,
     "end_time": "2023-11-09T08:38:15.031940",
     "exception": false,
     "start_time": "2023-11-09T08:31:57.221476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(T_0=30, T_mult=1, ave_kernel_size=301, batch_size=64, class_loss_weight=1.0, class_output_channels=1, competition_dir='/kaggle/input/child-mind-institute-detect-sleep-states', competition_name='dss', device='cuda', embedding_base_channels=16, eta_min=1e-09, event_df='/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv', event_loss_weight=1.0, event_output_channels=2, exp_category='earlysave', exp_dir='/kaggle/working/exp020_dense_chh_skffold_epoch30', exp_name='exp020_dense_chh_skffold_epoch30', folds=[0, 1, 2, 3, 4], group_key='series_id', input_channels=6, input_dir='/kaggle/input', key_df='/kaggle/input/datakey_unique_non_null.csv', logger_path='/kaggle/working/exp020_dense_chh_skffold_epoch30/train.log', lr=0.001, maxpool_kernel_size=11, model_type='input_target_downsample_dense', n_epoch=30, n_folds=5, num_workers=2, output_channels=2, output_dir='/kaggle/working', print_freq=50, pseudo_weight_exp='exp003', seed=42, series_df='/kaggle/input/targetdownsample_train_series_skffold.parquet', train_mode='train', user_name='taro', wandb_available=True, weight_decay=1e-06)\n",
      "--\n",
      "infer start\n",
      "split idx: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get anglez and enmo rolling mean and std\n",
      "-- fold0 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold0_model.pth\n",
      "split[0] fold[0] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold1 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold1_model.pth\n",
      "split[0] fold[1] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold2 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold2_model.pth\n",
      "split[0] fold[2] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold3 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold3_model.pth\n",
      "split[0] fold[3] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold4 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold4_model.pth\n",
      "split[0] fold[4] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "sub_df_split is saved as /kaggle/working/tmp_event/sub_df_split_0.csv\n",
      "split idx: 1\n",
      "get anglez and enmo rolling mean and std\n",
      "-- fold0 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold0_model.pth\n",
      "split[1] fold[0] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold1 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold1_model.pth\n",
      "split[1] fold[1] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold2 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold2_model.pth\n",
      "split[1] fold[2] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold3 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold3_model.pth\n",
      "split[1] fold[3] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold4 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold4_model.pth\n",
      "split[1] fold[4] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "sub_df_split is saved as /kaggle/working/tmp_event/sub_df_split_1.csv\n",
      "split idx: 2\n",
      "get anglez and enmo rolling mean and std\n",
      "-- fold0 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold0_model.pth\n",
      "split[2] fold[0] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold1 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold1_model.pth\n",
      "split[2] fold[1] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold2 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold2_model.pth\n",
      "split[2] fold[2] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold3 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold3_model.pth\n",
      "split[2] fold[3] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold4 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold4_model.pth\n",
      "split[2] fold[4] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "sub_df_split is saved as /kaggle/working/tmp_event/sub_df_split_2.csv\n",
      "split idx: 3\n",
      "get anglez and enmo rolling mean and std\n",
      "-- fold0 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold0_model.pth\n",
      "split[3] fold[0] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold1 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold1_model.pth\n",
      "split[3] fold[1] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold2 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold2_model.pth\n",
      "split[3] fold[2] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold3 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold3_model.pth\n",
      "split[3] fold[3] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold4 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold4_model.pth\n",
      "split[3] fold[4] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "sub_df_split is saved as /kaggle/working/tmp_event/sub_df_split_3.csv\n",
      "split idx: 4\n",
      "get anglez and enmo rolling mean and std\n",
      "-- fold0 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold0_model.pth\n",
      "split[4] fold[0] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.07 min\n",
      "-- fold1 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold1_model.pth\n",
      "split[4] fold[1] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.07 min\n",
      "-- fold2 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold2_model.pth\n",
      "split[4] fold[2] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.07 min\n",
      "-- fold3 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold3_model.pth\n",
      "split[4] fold[3] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.07 min\n",
      "-- fold4 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold4_model.pth\n",
      "split[4] fold[4] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.07 min\n",
      "sub_df_split is saved as /kaggle/working/tmp_event/sub_df_split_4.csv\n",
      "split idx: 5\n",
      "get anglez and enmo rolling mean and std\n",
      "-- fold0 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold0_model.pth\n",
      "split[5] fold[0] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold1 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold1_model.pth\n",
      "split[5] fold[1] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold2 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold2_model.pth\n",
      "split[5] fold[2] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold3 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold3_model.pth\n",
      "split[5] fold[3] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold4 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold4_model.pth\n",
      "split[5] fold[4] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "sub_df_split is saved as /kaggle/working/tmp_event/sub_df_split_5.csv\n",
      "split idx: 6\n",
      "get anglez and enmo rolling mean and std\n",
      "-- fold0 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold0_model.pth\n",
      "split[6] fold[0] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold1 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold1_model.pth\n",
      "split[6] fold[1] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold2 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold2_model.pth\n",
      "split[6] fold[2] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold3 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold3_model.pth\n",
      "split[6] fold[3] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold4 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold4_model.pth\n",
      "split[6] fold[4] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "sub_df_split is saved as /kaggle/working/tmp_event/sub_df_split_6.csv\n",
      "split idx: 7\n",
      "get anglez and enmo rolling mean and std\n",
      "-- fold0 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold0_model.pth\n",
      "split[7] fold[0] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold1 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold1_model.pth\n",
      "split[7] fold[1] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold2 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold2_model.pth\n",
      "split[7] fold[2] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold3 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold3_model.pth\n",
      "split[7] fold[3] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "-- fold4 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold4_model.pth\n",
      "split[7] fold[4] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.05 min\n",
      "sub_df_split is saved as /kaggle/working/tmp_event/sub_df_split_7.csv\n",
      "split idx: 8\n",
      "get anglez and enmo rolling mean and std\n",
      "-- fold0 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold0_model.pth\n",
      "split[8] fold[0] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.07 min\n",
      "-- fold1 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold1_model.pth\n",
      "split[8] fold[1] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.07 min\n",
      "-- fold2 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold2_model.pth\n",
      "split[8] fold[2] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.07 min\n",
      "-- fold3 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold3_model.pth\n",
      "split[8] fold[3] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.07 min\n",
      "-- fold4 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold4_model.pth\n",
      "split[8] fold[4] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.03 min\n",
      " >> oof_df created. elapsed time: 0.07 min\n",
      "sub_df_split is saved as /kaggle/working/tmp_event/sub_df_split_8.csv\n",
      "split idx: 9\n",
      "get anglez and enmo rolling mean and std\n",
      "-- fold0 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold0_model.pth\n",
      "split[9] fold[0] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.05 min\n",
      " >> oof_df created. elapsed time: 0.08 min\n",
      "-- fold1 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold1_model.pth\n",
      "split[9] fold[1] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.05 min\n",
      " >> oof_df created. elapsed time: 0.08 min\n",
      "-- fold2 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold2_model.pth\n",
      "split[9] fold[2] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.05 min\n",
      " >> oof_df created. elapsed time: 0.08 min\n",
      "-- fold3 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold3_model.pth\n",
      "split[9] fold[3] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.05 min\n",
      " >> oof_df created. elapsed time: 0.08 min\n",
      "-- fold4 inference start --\n",
      "model type =  input_target_downsample_dense\n",
      "model loading /kaggle/working/exp020_dense_chh_skffold_epoch30/fold4_model.pth\n",
      "split[9] fold[4] prediction finished.\n",
      "creating oof_df ... merging oof_df\n",
      "merge elapsed time: 0.05 min\n",
      " >> oof_df created. elapsed time: 0.08 min\n",
      "sub_df_split is saved as /kaggle/working/tmp_event/sub_df_split_9.csv\n",
      "sub_df data num : 92286\n"
     ]
    }
   ],
   "source": [
    "config = yaml.load(open(config_path, \"r\"), Loader=yaml.SafeLoader)\n",
    "config = argparse.Namespace(**config)\n",
    "\n",
    "# fold 0 だけにしてみる\n",
    "# config.folds = [0]\n",
    "\n",
    "print(config)\n",
    "print(\"--\")\n",
    "print(\"infer start\")\n",
    "sub_df = inference(config, exp_dir, exp_name, series_df_path, tmp_file_path, split_num=dataframe_split_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e773fd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T08:38:17.359913Z",
     "iopub.status.busy": "2023-11-09T08:38:17.359555Z",
     "iopub.status.idle": "2023-11-09T08:38:17.490072Z",
     "shell.execute_reply": "2023-11-09T08:38:17.489155Z"
    },
    "papermill": {
     "duration": 0.150834,
     "end_time": "2023-11-09T08:38:17.492130",
     "exception": false,
     "start_time": "2023-11-09T08:38:17.341296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>series_id</th>\n",
       "      <th>step</th>\n",
       "      <th>event</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>0</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.057968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>612</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.025244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>636</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.017577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>2352</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.012584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>038441c925bb</td>\n",
       "      <td>2856</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.010292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92281</th>\n",
       "      <td>92281</td>\n",
       "      <td>fe90110788d2</td>\n",
       "      <td>591708</td>\n",
       "      <td>onset</td>\n",
       "      <td>0.050172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92282</th>\n",
       "      <td>92282</td>\n",
       "      <td>fe90110788d2</td>\n",
       "      <td>591828</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.024425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92283</th>\n",
       "      <td>92283</td>\n",
       "      <td>fe90110788d2</td>\n",
       "      <td>591996</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.017652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92284</th>\n",
       "      <td>92284</td>\n",
       "      <td>fe90110788d2</td>\n",
       "      <td>592116</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.027364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92285</th>\n",
       "      <td>92285</td>\n",
       "      <td>fe90110788d2</td>\n",
       "      <td>592272</td>\n",
       "      <td>wakeup</td>\n",
       "      <td>0.032773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92286 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_id     series_id    step   event     score\n",
       "0           0  038441c925bb       0  wakeup  0.057968\n",
       "1           1  038441c925bb     612  wakeup  0.025244\n",
       "2           2  038441c925bb     636  wakeup  0.017577\n",
       "3           3  038441c925bb    2352   onset  0.012584\n",
       "4           4  038441c925bb    2856  wakeup  0.010292\n",
       "...       ...           ...     ...     ...       ...\n",
       "92281   92281  fe90110788d2  591708   onset  0.050172\n",
       "92282   92282  fe90110788d2  591828  wakeup  0.024425\n",
       "92283   92283  fe90110788d2  591996  wakeup  0.017652\n",
       "92284   92284  fe90110788d2  592116  wakeup  0.027364\n",
       "92285   92285  fe90110788d2  592272  wakeup  0.032773\n",
       "\n",
       "[92286 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sub_df[\"row_id\"] = range(len(sub_df))\n",
    "sub_df = sub_df[[\"row_id\", \"series_id\", \"step\", \"event\", \"score\"]]\n",
    "if len(sub_df) == 0:\n",
    "    sub_df = pd.read_csv(\"/kaggle/input/child-mind-institute-detect-sleep-states/sample_submission.csv\")\n",
    "# sub_df.to_csv(\"submission.csv\", index=False)\n",
    "display(sub_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3a1b085",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-09T08:38:17.528602Z",
     "iopub.status.busy": "2023-11-09T08:38:17.528268Z",
     "iopub.status.idle": "2023-11-09T08:38:21.283801Z",
     "shell.execute_reply": "2023-11-09T08:38:21.282738Z"
    },
    "papermill": {
     "duration": 3.776109,
     "end_time": "2023-11-09T08:38:21.286046",
     "exception": false,
     "start_time": "2023-11-09T08:38:17.509937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7195194264754544\n"
     ]
    }
   ],
   "source": [
    "from dss_metrics import score\n",
    "check_event_df = pd.read_csv(\"/kaggle/input/child-mind-institute-detect-sleep-states/train_events.csv\")\n",
    "check_event_df = check_event_df[check_event_df[\"series_id\"].isin(sub_df[\"series_id\"].unique())].dropna().reset_index(drop=True)\n",
    "print(score(check_event_df, sub_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab50786",
   "metadata": {
    "papermill": {
     "duration": 0.017263,
     "end_time": "2023-11-09T08:38:21.320851",
     "exception": false,
     "start_time": "2023-11-09T08:38:21.303588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 395.695189,
   "end_time": "2023-11-09T08:38:23.828183",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-09T08:31:48.132994",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
